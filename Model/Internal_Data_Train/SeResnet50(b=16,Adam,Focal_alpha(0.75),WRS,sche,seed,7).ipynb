{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8f1730-0357-450e-b3f1-c0617e0e6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,plot_confusion_matrix\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9cbd78-727b-43cc-b9bc-513a925754a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed = 42):\n",
    "    random.seed(seed) # python random seed 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # os 자체의 seed 고정\n",
    "    np.random.seed(seed) # numpy seed 고정 \n",
    "    torch.manual_seed(seed) # torch seed 고정\n",
    "    torch.cuda.manual_seed(seed) # cudnn seed 고정\n",
    "    torch.backends.cudnn.deterministic = True # cudnn seed 고정(nn.Conv2d)\n",
    "    torch.backends.cudnn.benchmark = False # CUDA 내부 연산에서 가장 빠른 알고리즘을 찾아 수행\n",
    "\n",
    "## DataLoader worker에 대한 seed 설정\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d956975-11e6-4e12-90c2-656b154a88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_path = '/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3(7_1.5_1.5)/normal_train_v3/*.jpg'\n",
    "train_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3(7_1.5_1.5)/abnormal_train_v3/*.jpg'\n",
    "valid_normal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3(7_1.5_1.5)/normal_val_v3/*.jpg'\n",
    "valid_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3(7_1.5_1.5)/abnormal_val_v3/*.jpg'\n",
    "test_normal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3(7_1.5_1.5)/normal_test_v3/*.jpg'\n",
    "test_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3(7_1.5_1.5)/abnormal_test_v3/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdadc3ce-eda1-46e6-9dc7-3ca1c0d3ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_normal : 406\n",
      "val_normal : 92\n",
      "test_normal : 92\n",
      "------------------------------------\n",
      "train_abnormal : 234\n",
      "val_abnormal : 51\n",
      "test_abnormal : 46\n"
     ]
    }
   ],
   "source": [
    "train_normal_glob = glob(train_normal_path)\n",
    "train_abnormal_glob = glob(train_abnormal_path)\n",
    "val_normal_glob = glob(valid_normal_path)\n",
    "val_abnormal_glob = glob(valid_abnormal_path)\n",
    "test_normal_glob = glob(test_normal_path)\n",
    "test_abnormal_glob = glob(test_abnormal_path)\n",
    "\n",
    "print('train_normal :', len(train_normal_glob))\n",
    "print('val_normal :', len(val_normal_glob))\n",
    "print('test_normal :', len(test_normal_glob))\n",
    "print('------------------------------------')\n",
    "print('train_abnormal :', len(train_abnormal_glob))\n",
    "print('val_abnormal :', len(val_abnormal_glob))\n",
    "print('test_abnormal :', len(test_abnormal_glob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f8fd4f-5b59-4a71-93b1-7039d2c32b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/base_seed\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684830b5-c141-4a30-b630-46e7d25914d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aov_Dysplasia_dataset(Dataset):\n",
    "    def __init__(self, normal_path, abnormal_path, transform=None):\n",
    "        #생성자, 데이터를 전처리 \n",
    "        self.normal_path_list = glob(normal_path)\n",
    "        self.abnormal_path_list = glob(abnormal_path)\n",
    "        print(len(self.normal_path_list))\n",
    "#         self.mode = mode \n",
    "    \n",
    "#         label = np.array([[0, 1], [1, 0]], dtype=np.float32)\n",
    "        \n",
    "#         self.label_list = []\n",
    "#         for i in self.normal_path_list:\n",
    "#             self.label_list.append(label[0])\n",
    "            \n",
    "#         for i in self.abnormal_path_list:\n",
    "#             self.label_list.append(label[1])\n",
    "            \n",
    "        label_policy = {\n",
    "            'normal': 0, \n",
    "            'abnormal': 1\n",
    "        }\n",
    "    \n",
    "        self.label_list= []\n",
    "        \n",
    "        for i in self.normal_path_list:\n",
    "            self.label_list.append(label_policy[\"normal\"])\n",
    "            \n",
    "        for i in self.abnormal_path_list:\n",
    "            self.label_list.append(label_policy[\"abnormal\"])\n",
    "        \n",
    "        self.total_img_path_list = self.normal_path_list + self.abnormal_path_list\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.total_img_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = cv2.imread(self.total_img_path_list[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # img = np.array(img, dtype=np.float32)\n",
    "        #들어오는 이미지의 컬러 형태가 BGR인지 RGB인지 모르기때문에 변형\n",
    "\n",
    "        \n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image'] \n",
    "            img = torch.tensor(np.array(img), dtype=torch.float32)\n",
    "            # img = torch.FloatTensor(img)\n",
    "            img = (img - torch.min(img)) / (torch.max(img)-torch.min(img))\n",
    "            \n",
    "            return {'img': img, 'label': label, 'filename': self.total_img_path_list[idx]}\n",
    "        \n",
    "        else:\n",
    "            # img = transformed['image']\n",
    "            img = torch.tensor(np.array(img), dtype=torch.float32)\n",
    "            # img = torch.FloatTensor(img)\n",
    "            img = (img - torch.min(img)) / (torch.max(img)-torch.min(img))\n",
    "            return{'img': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765fb65-6b9b-4a88-ba8c-b3a197520377",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.randint(1,10, size=(2,3,4))\n",
    "b= torch.FloatTensor(a)\n",
    "print(a)\n",
    "print(torch.min(a))\n",
    "print(a-torch.min(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96847f6e-8d55-4c2a-a712-271a8603b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://albumentations.ai/docs/api_reference/augmentations/transforms/\n",
    "import albumentations as A \n",
    "from  albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        # Contrast Limited Adaptive Histogram Equalization 적용\n",
    "#     A.CLAHE(p=1,clip_limit=(1, 3)),\n",
    "#     A.HorizontalFlip(p=0.3),\n",
    "    A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "    A.ShiftScaleRotate(shift_limit=0, scale_limit=(0.1, 0.2), rotate_limit=0, p=0.6, border_mode=cv2.BORDER_REPLICATE),\n",
    "    A.CLAHE(clip_limit=(1, 2), p=0.6),\n",
    "    A.RandomRotate90(p=0.7),\n",
    "    A.VerticalFlip(p=0.7),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
    "    # A.Normalize()\n",
    "    ToTensorV2()\n",
    "    ])\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7630b5-2c2f-411c-98d8-8bb75e3d2b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406\n",
      "92\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Aov_Dysplasia_dataset(train_normal_path, train_abnormal_path, transform = train_transform)\n",
    "valid_dataset = Aov_Dysplasia_dataset(valid_normal_path, valid_abnormal_path, transform = valid_transform)\n",
    "test_dataset = Aov_Dysplasia_dataset(test_normal_path, test_abnormal_path, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973e0b84-0a66-44f8-b195-7eb8924a3d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "train label 0 : 406\n",
      "train label 1 : 234\n",
      "[1.5763546798029557, 2.735042735042735]\n"
     ]
    }
   ],
   "source": [
    "# 각 dataset에서의 label값만 추출\n",
    "train_label_count = []\n",
    "for i in range(len(train_dataset)):\n",
    "    label = train_dataset[i]['label']\n",
    "    train_label_count.append(label)\n",
    "    \n",
    "print(len(train_label_count))\n",
    "\n",
    "sum_train = len(train_label_count)\n",
    "\n",
    "\n",
    "train_0_counts = train_label_count.count(0)\n",
    "train_1_counts = train_label_count.count(1)\n",
    "\n",
    "print('train label 0 :', train_0_counts)\n",
    "print('train label 1 :',train_1_counts)\n",
    "\n",
    "#클래스별 가중치 부여 => class 1에 가중치 높게 부여하게 됨\n",
    "train_0_weight = []\n",
    "train_1_weight = []\n",
    "train_weight = []\n",
    "\n",
    "train_0_weight.append(sum_train / train_0_counts) \n",
    "train_1_weight.append(sum_train / train_1_counts)\n",
    "\n",
    "train_weight = train_0_weight + train_1_weight\n",
    "\n",
    "print(train_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90cd8f-0876-4b56-831d-3c07f685c653",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becc79be-1256-42f4-a5cd-6ac617801db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터의 label에 해당되는 가중치\n",
    "weights = [train_weight[train_label_count[i]] for i in range(int(sum_train))] #해당 레이블마다의 가중치 비율\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(sum_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e6500-1a78-476f-8fcb-00de7a1b10de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0571fd-ed95-4d32-a1f6-963d33442ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader 생성\n",
    "batch_size= 16\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, worker_init_fn=seed_worker)\n",
    "train_dataloader_no = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle = True, worker_init_fn=seed_worker)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle = True, worker_init_fn=seed_worker)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle = False ,worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88415554-1d34-4268-879a-306ae1ca0708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset : 640\n",
      "valid_dataset : 143\n",
      "test_dataset : 138\n"
     ]
    }
   ],
   "source": [
    "print('train_dataset :',len(train_dataset))\n",
    "print('valid_dataset :',len(valid_dataset))\n",
    "print('test_dataset :',len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c4d57e2-c5d0-4f23-b450-2b2757c8534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0])\n",
      "tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "a= 0\n",
    "\n",
    "for data in train_dataloader:\n",
    "    print(data['label'])\n",
    "    a+=1        \n",
    "    \n",
    "    if a == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84827152-6a29-41c6-8d4a-2dcec2dd16af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae6fd6-ccb6-44c0-b51c-69ae57796d1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#이미지를 numpy형식으로 바꾸어주고 transpose를 통해 수정해주는 과정을 람다형식으로 정의\n",
    "fn_tonumpy = lambda x : x.to('cpu').detach().numpy().transpose(0,2,3,1)\n",
    "for batch_idx, i in enumerate(train_dataloader):\n",
    "    print(batch_idx+1)\n",
    "    for a in range(batch_size):\n",
    "        img = i['img']\n",
    "        label = i['label']\n",
    "        print(label.type)\n",
    "#         filename = i['filename']\n",
    "        #     filename = i['filename']\n",
    "        img = fn_tonumpy(img)[a]\n",
    "        #     print(filename)\n",
    "        print(img.shape)\n",
    "        print(img)\n",
    "#         print(filename[a])\n",
    "        print(label[a])\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c448f00-92d2-46b4-997f-7651113a6a79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "import timm\n",
    "# m = timm.create_model('seresnet50', pretrained=True)\n",
    "\n",
    "seresnet50_pretrained = timm.create_model('seresnet50', pretrained=True)\n",
    "print(seresnet50_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb7394-56bc-49af-9018-297366283ab6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "num_features = seresnet50_pretrained.fc.in_features\n",
    "seresnet50_pretrained.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "seresnet50_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46cd5138-fb83-400d-9bd9-efbe186b6bf8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu?  True\n",
      "Current gpu:  0\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crop2292/anaconda3/envs/hoon/lib/python3.6/site-packages/torch/cuda/memory.py:386: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0163],\n",
      "        [-0.0459],\n",
      "        [-0.1420]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "print('gpu? ', torch.cuda.is_available())\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print('Current gpu: ', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')\n",
    "    \n",
    "model = seresnet50_pretrained.to(device)\n",
    "x = torch.randn(3, 3, 224, 224).to(device)\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0753a5d8-66c2-4a13-a50b-2ce94b4264ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#summary(model, (3, 409, 465), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3347e31c-18ac-4bf7-b592-50ec2f3e6d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의(loss function) \n",
    "# 크로스 엔트로피 : 실제 값과 예측 값의 차이를 줄이기 위한 엔트로피\n",
    "# 다중 클래스 문제에서 잘 작동\n",
    "# loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# 옵티마이저 : Adam \n",
    "# model(신경망) 파라미터를 optimizer에 전달해줄 때 nn.Module의 parameters() 메소드를 사용\n",
    "# Karpathy's learning rate 사용 (3e-4)\n",
    "opt = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#scheduler\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "lr_scheduler = ExponentialLR(opt, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5db28ed7-ff38-4a6a-be4b-72bf51a64a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd26ad1d-3e47-435a-9975-6412ed9e77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.75):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = self.loss_fn.reduction  # mean, sum, etc..\n",
    "\n",
    "    def forward(self, pred, true):\n",
    "        bceloss = self.loss_fn(pred, true)\n",
    "\n",
    "        pred_prob = torch.sigmoid(pred)  # p  pt는 p가 true 이면 pt = p / false 이면 pt = 1 - p\n",
    "        alpha_factor = true * self.alpha + (1-true) * (1 - self.alpha)  # add balance\n",
    "        modulating_factor = torch.abs(true - pred_prob) ** self.gamma  # focal term\n",
    "        loss = alpha_factor * modulating_factor * bceloss  # bceloss에 이미 음수가 들어가 있음\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        \n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        \n",
    "        else:  # 'none'\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3e5f289-4267-4a90-9c8e-c906c10be409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_batch(output, target):\n",
    "    #max함수 안의 1 : 어느방향으로 max값을 찾을지를 의미. \n",
    "    output_sig = torch.sigmoid(output)\n",
    "    y_pred = output_sig.cpu()\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "    \n",
    "    preds_batch_list = []\n",
    "    y_pred_list = y_pred.detach().cpu().numpy().tolist()\n",
    "    preds_batch_list.append(y_pred_list)\n",
    "    \n",
    "    labels_batch_list =[]\n",
    "    labels_list = target.detach().cpu().numpy().tolist()\n",
    "    labels_batch_list.append(labels_list)\n",
    "    \n",
    "    correct_num = y_pred.eq(target.cpu()).int().sum()\n",
    "    \n",
    "    # https://junstar92.tistory.com/121\n",
    "    #https://bigdatadiary0819.tistory.com/54\n",
    "#     corrects = pred.eq(target).sum().item()\n",
    "    return correct_num, preds_batch_list,labels_batch_list\n",
    "\n",
    "\n",
    "# function to calculate loss per mini-batch\n",
    "def loss_batch(output, target, opt=None):\n",
    "    \n",
    "    \n",
    "#     target = torch.FloatTensor(target)\n",
    "#     print(output)\n",
    "#     print(target)\n",
    "    \n",
    "\n",
    "# 여기서 target값은 1차원이기 때문에 마지막 layer에서 나오는 결과를 1개의 출력으로\n",
    "    fl_loss = FocalLoss().forward(output, target)\n",
    "    metric_b, preds_batch_list,labels_batch_list = metric_batch(output, target)\n",
    "\n",
    "#     배치 사이즈 만큼의 데이터가 들어가서 forward train을 하고 backward로 \n",
    "#     optimize를 진행합니다. 이게 1step \n",
    "#     step마다 계산된 가중치를 다시 제로로 만들고 다음 배치 데이터를 \n",
    "#     forward/backward해야 하므로 optimizer.zero_grad를 꼭 넣어준다.\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        fl_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return fl_loss.item(), metric_b, preds_batch_list,labels_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbdb5aaa-3574-42b3-b4c5-79aecb854689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_epoch(model, dataset_dl, sanity_check=False, opt=None):\n",
    "    #sanity_check가 true인 경우 1epoch만 학습하고 더이상 학습하지 않는다.\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_dataset_dl = len(dataset_dl)\n",
    "    len_dataset = len(dataset_dl.dataset)\n",
    "    preds_running_list = []\n",
    "    labels_running_list = []\n",
    "#     print(len_data)\n",
    "#     print(len(dataset_dl))\n",
    "    \n",
    "    \n",
    "    for data in dataset_dl:\n",
    "#         inputs = data\n",
    "#     for a in range (i):\n",
    "        inputs = data['img']\n",
    "#         print(inputs.shape)\n",
    "        labels = data['label']\n",
    "#         print(labels.shape)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device, dtype = torch.float32)\n",
    "        output = torch.squeeze(model(inputs))\n",
    "    \n",
    "#     for i, data in enumerate(dataset_dl):\n",
    "#         inputs = data\n",
    "#      for a in range (i):\n",
    "#         inputs = data['img']\n",
    "#          print(inputs.shape)\n",
    "#         labels = data['label']\n",
    "#          print(labels.shape)\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         output = model(inputs)\n",
    "\n",
    "#         print(inputs.type)\n",
    "#         print(output.type)\n",
    "#         print(labels.type)\n",
    "        \n",
    "        \n",
    "        loss_b, metric_b, preds_batch_list,labels_batch_list = loss_batch(output, labels, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        preds_running_list.extend(preds_batch_list)\n",
    "        labels_running_list.extend(labels_batch_list)\n",
    "\n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "            \n",
    "    average_loss = running_loss / len_dataset_dl\n",
    "    average_metric = running_metric / len_dataset\n",
    "#     print(average_loss)\n",
    "    \n",
    "    return average_loss, average_metric, preds_running_list, labels_running_list      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "313423a9-520e-4eb9-a8c3-e9bee6c3996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to start training\n",
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    #가장 잘 나온 weight를 저장.\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    #This is useful for finding lowest values for something.\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch+1, num_epochs, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric, preds_train_list, labels_train_list = loss_epoch(model, train_dl, sanity_check, opt)\n",
    "        #epoch마다 loss값과 정확도 값 확인\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "        \n",
    "        # confusion matrix를 그리기 위해 label과 prediction한 결과를 한곳으로 모아주기\n",
    "        preds_train_list_sum = sum(preds_train_list,[])\n",
    "        labels_train_list_sum = sum(labels_train_list,[])\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "# model.eval() : 해당 모델의 모든 레이어가 evaluation model에 들어가게 해주는 것. \n",
    "# 학습할 때만 필요한 dropout, batchnorm등의 기능을 비황성화 시키는 것.\n",
    "# torch.no_grad() : gradient계산 context를 비활성화 해주는 역할.    \n",
    "        model.eval()\n",
    "    \n",
    "        # valid data\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric, preds_val_list, labels_val_list = loss_epoch(model, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        train_accuracy = 100*train_metric\n",
    "        val_accuracy = 100*val_metric\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch+1)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch+1)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch+1)\n",
    "        writer.add_scalar('Accuracy/val', val_accuracy, epoch+1)\n",
    "        \n",
    "        print('train loss: %.6f , accuracy: %.2f, time: %.4f min' %(train_loss, train_accuracy, (time.time()-start_time)/60))\n",
    "        print('val loss: %.6f , accuracy: %.2f, time: %.4f min' %(val_loss, val_accuracy, (time.time()-start_time)/60))\n",
    "        \n",
    "        preds_val_list_sum = sum(preds_val_list, [])\n",
    "        labels_val_list_sum = sum(labels_val_list, [])\n",
    "#         print(preds_val_list)\n",
    "#         print(len(preds_val_list))\n",
    "#         print(labels_val_list)\n",
    "#         print(len(labels_val_list))\n",
    "        \n",
    "        print('train_confusion_matrix')\n",
    "        print(confusion_matrix(labels_train_list_sum,preds_train_list_sum))\n",
    "        print('val_confustion_matrix')\n",
    "        print(confusion_matrix(labels_val_list_sum,preds_val_list_sum))\n",
    "        print(classification_report(labels_val_list_sum,preds_val_list_sum))\n",
    "        print(accuracy_score(labels_val_list_sum,preds_val_list_sum))\n",
    "        print('-'*30)\n",
    "\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "449c186e-0fd4-486d-b4d1-ed30f059b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {\n",
    "    'num_epochs':150,\n",
    "    'optimizer':opt,\n",
    "    'train_dl':train_dataloader,\n",
    "    'val_dl':valid_dataloader,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':'/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/weights_file/seresnet50(b=16,Adam,Focal_alpha(0.75),WRS,sche,seed,7)_weights_pt',\n",
    "}\n",
    "\n",
    "#만약 파일이 존재하지 않으면 새로운 파일 생성\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSerror:\n",
    "        print('Error')\n",
    "createFolder('Resnet_weights_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75aeb1c6-f9bb-4259-9a20-2c3788e58c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/runs/seresnet50(b=16,Adam,Focal_alpha(0.75),WRS,sche,seed,7)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7f67828-f27c-44ef-863e-b4dcdd2f8297",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, current lr=0.0001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.072424 , accuracy: 50.00, time: 0.2565 min\n",
      "val loss: 0.068970 , accuracy: 37.06, time: 0.2565 min\n",
      "train_confusion_matrix\n",
      "[[ 34 286]\n",
      " [ 34 286]]\n",
      "val_confustion_matrix\n",
      "[[ 2 90]\n",
      " [ 0 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04        92\n",
      "         1.0       0.36      1.00      0.53        51\n",
      "\n",
      "    accuracy                           0.37       143\n",
      "   macro avg       0.68      0.51      0.29       143\n",
      "weighted avg       0.77      0.37      0.22       143\n",
      "\n",
      "0.3706293706293706\n",
      "------------------------------\n",
      "Epoch 2/150, current lr=9.5e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.043422 , accuracy: 64.22, time: 0.5085 min\n",
      "val loss: 0.050754 , accuracy: 64.34, time: 0.5085 min\n",
      "train_confusion_matrix\n",
      "[[ 86 222]\n",
      " [  7 325]]\n",
      "val_confustion_matrix\n",
      "[[42 50]\n",
      " [ 1 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.46      0.62        92\n",
      "         1.0       0.50      0.98      0.66        51\n",
      "\n",
      "    accuracy                           0.64       143\n",
      "   macro avg       0.74      0.72      0.64       143\n",
      "weighted avg       0.81      0.64      0.64       143\n",
      "\n",
      "0.6433566433566433\n",
      "------------------------------\n",
      "Epoch 3/150, current lr=9.025e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.026781 , accuracy: 79.84, time: 0.7587 min\n",
      "val loss: 0.038451 , accuracy: 76.22, time: 0.7587 min\n",
      "train_confusion_matrix\n",
      "[[206 107]\n",
      " [ 22 305]]\n",
      "val_confustion_matrix\n",
      "[[64 28]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.70      0.79        92\n",
      "         1.0       0.62      0.88      0.73        51\n",
      "\n",
      "    accuracy                           0.76       143\n",
      "   macro avg       0.77      0.79      0.76       143\n",
      "weighted avg       0.81      0.76      0.77       143\n",
      "\n",
      "0.7622377622377622\n",
      "------------------------------\n",
      "Epoch 4/150, current lr=8.573749999999999e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.019673 , accuracy: 83.12, time: 1.0130 min\n",
      "val loss: 0.036660 , accuracy: 75.52, time: 1.0130 min\n",
      "train_confusion_matrix\n",
      "[[243  83]\n",
      " [ 25 289]]\n",
      "val_confustion_matrix\n",
      "[[70 22]\n",
      " [13 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.76      0.80        92\n",
      "         1.0       0.63      0.75      0.68        51\n",
      "\n",
      "    accuracy                           0.76       143\n",
      "   macro avg       0.74      0.75      0.74       143\n",
      "weighted avg       0.77      0.76      0.76       143\n",
      "\n",
      "0.7552447552447552\n",
      "------------------------------\n",
      "Epoch 5/150, current lr=8.145062499999998e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.014970 , accuracy: 87.81, time: 1.2775 min\n",
      "val loss: 0.030265 , accuracy: 75.52, time: 1.2775 min\n",
      "train_confusion_matrix\n",
      "[[262  50]\n",
      " [ 28 300]]\n",
      "val_confustion_matrix\n",
      "[[67 25]\n",
      " [10 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.73      0.79        92\n",
      "         1.0       0.62      0.80      0.70        51\n",
      "\n",
      "    accuracy                           0.76       143\n",
      "   macro avg       0.75      0.77      0.75       143\n",
      "weighted avg       0.78      0.76      0.76       143\n",
      "\n",
      "0.7552447552447552\n",
      "------------------------------\n",
      "Epoch 6/150, current lr=7.737809374999998e-05\n",
      "train loss: 0.012652 , accuracy: 88.28, time: 1.5284 min\n",
      "val loss: 0.034423 , accuracy: 77.62, time: 1.5284 min\n",
      "train_confusion_matrix\n",
      "[[266  54]\n",
      " [ 21 299]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [20 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.87      0.83        92\n",
      "         1.0       0.72      0.61      0.66        51\n",
      "\n",
      "    accuracy                           0.78       143\n",
      "   macro avg       0.76      0.74      0.75       143\n",
      "weighted avg       0.77      0.78      0.77       143\n",
      "\n",
      "0.7762237762237763\n",
      "------------------------------\n",
      "Epoch 7/150, current lr=7.350918906249998e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.009075 , accuracy: 90.00, time: 1.7629 min\n",
      "val loss: 0.027164 , accuracy: 80.42, time: 1.7629 min\n",
      "train_confusion_matrix\n",
      "[[287  48]\n",
      " [ 16 289]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.79      0.84        92\n",
      "         1.0       0.69      0.82      0.75        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.79      0.81      0.79       143\n",
      "weighted avg       0.82      0.80      0.81       143\n",
      "\n",
      "0.8041958041958042\n",
      "------------------------------\n",
      "Epoch 8/150, current lr=6.983372960937497e-05\n",
      "train loss: 0.004626 , accuracy: 94.84, time: 1.9828 min\n",
      "val loss: 0.028791 , accuracy: 79.72, time: 1.9828 min\n",
      "train_confusion_matrix\n",
      "[[292  23]\n",
      " [ 10 315]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [13 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.83      0.84        92\n",
      "         1.0       0.70      0.75      0.72        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.78      0.79      0.78       143\n",
      "weighted avg       0.80      0.80      0.80       143\n",
      "\n",
      "0.7972027972027972\n",
      "------------------------------\n",
      "Epoch 9/150, current lr=6.634204312890622e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.008686 , accuracy: 92.03, time: 2.2104 min\n",
      "val loss: 0.025747 , accuracy: 83.92, time: 2.2104 min\n",
      "train_confusion_matrix\n",
      "[[284  34]\n",
      " [ 17 305]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.85      0.87        92\n",
      "         1.0       0.75      0.82      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.84      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 10/150, current lr=6.30249409724609e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.005266 , accuracy: 93.28, time: 2.4377 min\n",
      "val loss: 0.023318 , accuracy: 84.62, time: 2.4377 min\n",
      "train_confusion_matrix\n",
      "[[281  29]\n",
      " [ 14 316]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88        92\n",
      "         1.0       0.76      0.82      0.79        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.84      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 11/150, current lr=5.987369392383786e-05\n",
      "train loss: 0.004222 , accuracy: 94.22, time: 2.6673 min\n",
      "val loss: 0.023940 , accuracy: 80.42, time: 2.6673 min\n",
      "train_confusion_matrix\n",
      "[[284  29]\n",
      " [  8 319]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.79      0.84        92\n",
      "         1.0       0.69      0.82      0.75        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.79      0.81      0.79       143\n",
      "weighted avg       0.82      0.80      0.81       143\n",
      "\n",
      "0.8041958041958042\n",
      "------------------------------\n",
      "Epoch 12/150, current lr=5.688000922764596e-05\n",
      "train loss: 0.004902 , accuracy: 93.75, time: 2.8983 min\n",
      "val loss: 0.031128 , accuracy: 83.22, time: 2.8983 min\n",
      "train_confusion_matrix\n",
      "[[285  27]\n",
      " [ 13 315]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [11 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87        92\n",
      "         1.0       0.75      0.78      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.82      0.82       143\n",
      "weighted avg       0.83      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 13/150, current lr=5.4036008766263664e-05\n",
      "train loss: 0.005119 , accuracy: 94.06, time: 3.1288 min\n",
      "val loss: 0.032309 , accuracy: 79.72, time: 3.1288 min\n",
      "train_confusion_matrix\n",
      "[[288  31]\n",
      " [  7 314]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [17 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.85        92\n",
      "         1.0       0.74      0.67      0.70        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.78      0.77      0.77       143\n",
      "weighted avg       0.79      0.80      0.79       143\n",
      "\n",
      "0.7972027972027972\n",
      "------------------------------\n",
      "Epoch 14/150, current lr=5.133420832795048e-05\n",
      "train loss: 0.006013 , accuracy: 92.34, time: 3.3637 min\n",
      "val loss: 0.036336 , accuracy: 79.72, time: 3.3637 min\n",
      "train_confusion_matrix\n",
      "[[290  34]\n",
      " [ 15 301]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [18 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.88      0.85        92\n",
      "         1.0       0.75      0.65      0.69        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.78      0.76      0.77       143\n",
      "weighted avg       0.79      0.80      0.79       143\n",
      "\n",
      "0.7972027972027972\n",
      "------------------------------\n",
      "Epoch 15/150, current lr=4.876749791155295e-05\n",
      "train loss: 0.004544 , accuracy: 93.28, time: 3.5982 min\n",
      "val loss: 0.027639 , accuracy: 82.52, time: 3.5983 min\n",
      "train_confusion_matrix\n",
      "[[296  33]\n",
      " [ 10 301]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [13 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.87      0.86        92\n",
      "         1.0       0.76      0.75      0.75        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.81      0.81       143\n",
      "weighted avg       0.82      0.83      0.82       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 16/150, current lr=4.6329123015975305e-05\n",
      "train loss: 0.006827 , accuracy: 91.88, time: 3.8367 min\n",
      "val loss: 0.024286 , accuracy: 79.02, time: 3.8367 min\n",
      "train_confusion_matrix\n",
      "[[294  40]\n",
      " [ 12 294]]\n",
      "val_confustion_matrix\n",
      "[[68 24]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.74      0.82        92\n",
      "         1.0       0.65      0.88      0.75        51\n",
      "\n",
      "    accuracy                           0.79       143\n",
      "   macro avg       0.79      0.81      0.78       143\n",
      "weighted avg       0.82      0.79      0.79       143\n",
      "\n",
      "0.7902097902097902\n",
      "------------------------------\n",
      "Epoch 17/150, current lr=4.4012666865176535e-05\n",
      "train loss: 0.004828 , accuracy: 95.00, time: 4.0776 min\n",
      "val loss: 0.023641 , accuracy: 86.71, time: 4.0776 min\n",
      "train_confusion_matrix\n",
      "[[311  28]\n",
      " [  4 297]]\n",
      "val_confustion_matrix\n",
      "[[82 10]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.90        92\n",
      "         1.0       0.81      0.82      0.82        51\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.85      0.86      0.86       143\n",
      "weighted avg       0.87      0.87      0.87       143\n",
      "\n",
      "0.8671328671328671\n",
      "------------------------------\n",
      "Epoch 18/150, current lr=4.181203352191771e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.007062 , accuracy: 91.88, time: 4.3250 min\n",
      "val loss: 0.023186 , accuracy: 83.92, time: 4.3250 min\n",
      "train_confusion_matrix\n",
      "[[283  33]\n",
      " [ 19 305]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 19/150, current lr=3.972143184582182e-05\n",
      "train loss: 0.005370 , accuracy: 94.22, time: 4.5623 min\n",
      "val loss: 0.024005 , accuracy: 81.82, time: 4.5624 min\n",
      "train_confusion_matrix\n",
      "[[277  27]\n",
      " [ 10 326]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.79      0.85        92\n",
      "         1.0       0.70      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 20/150, current lr=3.7735360253530726e-05\n",
      "train loss: 0.002940 , accuracy: 96.72, time: 4.7994 min\n",
      "val loss: 0.026772 , accuracy: 82.52, time: 4.7994 min\n",
      "train_confusion_matrix\n",
      "[[306  18]\n",
      " [  3 313]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.79      0.85        92\n",
      "         1.0       0.70      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 21/150, current lr=3.584859224085419e-05\n",
      "train loss: 0.003365 , accuracy: 96.72, time: 5.0452 min\n",
      "val loss: 0.023921 , accuracy: 86.01, time: 5.0452 min\n",
      "train_confusion_matrix\n",
      "[[291  16]\n",
      " [  5 328]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89        92\n",
      "         1.0       0.77      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.87      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 22/150, current lr=3.405616262881148e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.004345 , accuracy: 95.16, time: 5.2982 min\n",
      "val loss: 0.020772 , accuracy: 83.92, time: 5.2982 min\n",
      "train_confusion_matrix\n",
      "[[286  19]\n",
      " [ 12 323]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 23/150, current lr=3.2353354497370904e-05\n",
      "train loss: 0.003397 , accuracy: 94.84, time: 5.5352 min\n",
      "val loss: 0.024480 , accuracy: 82.52, time: 5.5352 min\n",
      "train_confusion_matrix\n",
      "[[275  26]\n",
      " [  7 332]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.83      0.86        92\n",
      "         1.0       0.72      0.82      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.82      0.81       143\n",
      "weighted avg       0.83      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 24/150, current lr=3.0735686772502355e-05\n",
      "train loss: 0.003688 , accuracy: 94.22, time: 5.7802 min\n",
      "val loss: 0.025268 , accuracy: 85.31, time: 5.7802 min\n",
      "train_confusion_matrix\n",
      "[[282  26]\n",
      " [ 11 321]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [10 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.88      0.89        92\n",
      "         1.0       0.79      0.80      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.84      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 25/150, current lr=2.9198902433877236e-05\n",
      "train loss: 0.002750 , accuracy: 95.94, time: 6.0253 min\n",
      "val loss: 0.022641 , accuracy: 85.31, time: 6.0253 min\n",
      "train_confusion_matrix\n",
      "[[283  21]\n",
      " [  5 331]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88        92\n",
      "         1.0       0.76      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 26/150, current lr=2.7738957312183373e-05\n",
      "train loss: 0.003533 , accuracy: 95.00, time: 6.2682 min\n",
      "val loss: 0.022748 , accuracy: 83.92, time: 6.2682 min\n",
      "train_confusion_matrix\n",
      "[[304  26]\n",
      " [  6 304]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 27/150, current lr=2.6352009446574204e-05\n",
      "train loss: 0.003986 , accuracy: 94.53, time: 6.5225 min\n",
      "val loss: 0.023470 , accuracy: 85.31, time: 6.5225 min\n",
      "train_confusion_matrix\n",
      "[[287  31]\n",
      " [  4 318]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 28/150, current lr=2.5034408974245492e-05\n",
      "train loss: 0.003066 , accuracy: 95.31, time: 6.7800 min\n",
      "val loss: 0.022328 , accuracy: 82.52, time: 6.7800 min\n",
      "train_confusion_matrix\n",
      "[[295  23]\n",
      " [  7 315]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.80      0.86        92\n",
      "         1.0       0.71      0.86      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 29/150, current lr=2.3782688525533216e-05\n",
      "train loss: 0.004382 , accuracy: 92.97, time: 7.0343 min\n",
      "val loss: 0.023209 , accuracy: 83.92, time: 7.0343 min\n",
      "train_confusion_matrix\n",
      "[[316  40]\n",
      " [  5 279]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 30/150, current lr=2.2593554099256555e-05\n",
      "train loss: 0.002105 , accuracy: 96.72, time: 7.2838 min\n",
      "val loss: 0.025427 , accuracy: 80.42, time: 7.2838 min\n",
      "train_confusion_matrix\n",
      "[[312  15]\n",
      " [  6 307]]\n",
      "val_confustion_matrix\n",
      "[[71 21]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.77      0.84        92\n",
      "         1.0       0.68      0.86      0.76        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.79      0.82      0.80       143\n",
      "weighted avg       0.83      0.80      0.81       143\n",
      "\n",
      "0.8041958041958042\n",
      "------------------------------\n",
      "Epoch 31/150, current lr=2.1463876394293726e-05\n",
      "train loss: 0.003889 , accuracy: 93.91, time: 7.5348 min\n",
      "val loss: 0.022540 , accuracy: 84.62, time: 7.5348 min\n",
      "train_confusion_matrix\n",
      "[[273  29]\n",
      " [ 10 328]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88        92\n",
      "         1.0       0.76      0.82      0.79        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.84      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 32/150, current lr=2.039068257457904e-05\n",
      "train loss: 0.002598 , accuracy: 95.94, time: 7.7767 min\n",
      "val loss: 0.028105 , accuracy: 84.62, time: 7.7768 min\n",
      "train_confusion_matrix\n",
      "[[306  24]\n",
      " [  2 308]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [11 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88        92\n",
      "         1.0       0.78      0.78      0.78        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.83      0.83       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 33/150, current lr=1.9371148445850086e-05\n",
      "train loss: 0.004402 , accuracy: 94.06, time: 8.0164 min\n",
      "val loss: 0.024181 , accuracy: 83.22, time: 8.0165 min\n",
      "train_confusion_matrix\n",
      "[[279  28]\n",
      " [ 10 323]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [11 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87        92\n",
      "         1.0       0.75      0.78      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.82      0.82       143\n",
      "weighted avg       0.83      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 34/150, current lr=1.840259102355758e-05\n",
      "train loss: 0.003362 , accuracy: 95.31, time: 8.2867 min\n",
      "val loss: 0.022978 , accuracy: 84.62, time: 8.2868 min\n",
      "train_confusion_matrix\n",
      "[[303  25]\n",
      " [  5 307]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88        92\n",
      "         1.0       0.75      0.86      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 35/150, current lr=1.74824614723797e-05\n",
      "train loss: 0.002528 , accuracy: 96.09, time: 8.5547 min\n",
      "val loss: 0.020946 , accuracy: 79.72, time: 8.5547 min\n",
      "train_confusion_matrix\n",
      "[[286  20]\n",
      " [  5 329]]\n",
      "val_confustion_matrix\n",
      "[[70 22]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.76      0.83        92\n",
      "         1.0       0.67      0.86      0.75        51\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.79      0.81      0.79       143\n",
      "weighted avg       0.82      0.80      0.80       143\n",
      "\n",
      "0.7972027972027972\n",
      "------------------------------\n",
      "Epoch 36/150, current lr=1.6608338398760715e-05\n",
      "train loss: 0.003759 , accuracy: 93.91, time: 8.8082 min\n",
      "val loss: 0.023139 , accuracy: 83.22, time: 8.8082 min\n",
      "train_confusion_matrix\n",
      "[[296  36]\n",
      " [  3 305]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86        92\n",
      "         1.0       0.72      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 37/150, current lr=1.5777921478822678e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.004893 , accuracy: 93.91, time: 9.0654 min\n",
      "val loss: 0.020426 , accuracy: 84.62, time: 9.0655 min\n",
      "train_confusion_matrix\n",
      "[[290  34]\n",
      " [  5 311]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 38/150, current lr=1.4989025404881544e-05\n",
      "train loss: 0.003033 , accuracy: 95.94, time: 9.3082 min\n",
      "val loss: 0.021515 , accuracy: 83.92, time: 9.3082 min\n",
      "train_confusion_matrix\n",
      "[[309  19]\n",
      " [  7 305]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 39/150, current lr=1.4239574134637466e-05\n",
      "train loss: 0.004229 , accuracy: 94.38, time: 9.5520 min\n",
      "val loss: 0.024685 , accuracy: 85.31, time: 9.5520 min\n",
      "train_confusion_matrix\n",
      "[[289  27]\n",
      " [  9 315]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 40/150, current lr=1.3527595427905592e-05\n",
      "train loss: 0.003587 , accuracy: 94.22, time: 9.7947 min\n",
      "val loss: 0.022242 , accuracy: 83.92, time: 9.7947 min\n",
      "train_confusion_matrix\n",
      "[[288  27]\n",
      " [ 10 315]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 41/150, current lr=1.2851215656510312e-05\n",
      "train loss: 0.003212 , accuracy: 96.25, time: 10.0374 min\n",
      "val loss: 0.023234 , accuracy: 83.92, time: 10.0375 min\n",
      "train_confusion_matrix\n",
      "[[308  17]\n",
      " [  7 308]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 42/150, current lr=1.2208654873684796e-05\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.003676 , accuracy: 94.22, time: 10.2845 min\n",
      "val loss: 0.019844 , accuracy: 83.22, time: 10.2845 min\n",
      "train_confusion_matrix\n",
      "[[288  25]\n",
      " [ 12 315]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 43/150, current lr=1.1598222130000555e-05\n",
      "train loss: 0.002839 , accuracy: 95.78, time: 10.5294 min\n",
      "val loss: 0.024930 , accuracy: 84.62, time: 10.5294 min\n",
      "train_confusion_matrix\n",
      "[[307  21]\n",
      " [  6 306]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88        92\n",
      "         1.0       0.76      0.82      0.79        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.84      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 44/150, current lr=1.1018311023500527e-05\n",
      "train loss: 0.004143 , accuracy: 94.84, time: 10.7761 min\n",
      "val loss: 0.020400 , accuracy: 83.22, time: 10.7761 min\n",
      "train_confusion_matrix\n",
      "[[277  20]\n",
      " [ 13 330]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.84      0.87        92\n",
      "         1.0       0.74      0.82      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 45/150, current lr=1.04673954723255e-05\n",
      "train loss: 0.004342 , accuracy: 94.06, time: 11.0245 min\n",
      "val loss: 0.022485 , accuracy: 83.22, time: 11.0245 min\n",
      "train_confusion_matrix\n",
      "[[294  31]\n",
      " [  7 308]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 46/150, current lr=9.944025698709225e-06\n",
      "train loss: 0.003707 , accuracy: 95.78, time: 11.2659 min\n",
      "val loss: 0.021244 , accuracy: 86.01, time: 11.2659 min\n",
      "train_confusion_matrix\n",
      "[[271  18]\n",
      " [  9 342]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 47/150, current lr=9.446824413773763e-06\n",
      "train loss: 0.004825 , accuracy: 93.44, time: 11.4990 min\n",
      "val loss: 0.024725 , accuracy: 86.01, time: 11.4990 min\n",
      "train_confusion_matrix\n",
      "[[303  31]\n",
      " [ 11 295]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 48/150, current lr=8.974483193085074e-06\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.003170 , accuracy: 95.31, time: 11.7256 min\n",
      "val loss: 0.018637 , accuracy: 86.01, time: 11.7256 min\n",
      "train_confusion_matrix\n",
      "[[298  24]\n",
      " [  6 312]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89        92\n",
      "         1.0       0.77      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.87      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 49/150, current lr=8.52575903343082e-06\n",
      "train loss: 0.003212 , accuracy: 95.31, time: 11.9520 min\n",
      "val loss: 0.024990 , accuracy: 84.62, time: 11.9520 min\n",
      "train_confusion_matrix\n",
      "[[296  26]\n",
      " [  4 314]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [10 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.87      0.88        92\n",
      "         1.0       0.77      0.80      0.79        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.84      0.83       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 50/150, current lr=8.09947108175928e-06\n",
      "train loss: 0.002785 , accuracy: 94.69, time: 12.1761 min\n",
      "val loss: 0.021436 , accuracy: 85.31, time: 12.1761 min\n",
      "train_confusion_matrix\n",
      "[[293  24]\n",
      " [ 10 313]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 51/150, current lr=7.694497527671315e-06\n",
      "train loss: 0.003150 , accuracy: 95.62, time: 12.4006 min\n",
      "val loss: 0.023111 , accuracy: 86.01, time: 12.4007 min\n",
      "train_confusion_matrix\n",
      "[[287  20]\n",
      " [  8 325]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 52/150, current lr=7.309772651287749e-06\n",
      "train loss: 0.004174 , accuracy: 96.09, time: 12.6250 min\n",
      "val loss: 0.023473 , accuracy: 85.31, time: 12.6250 min\n",
      "train_confusion_matrix\n",
      "[[296  18]\n",
      " [  7 319]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88        92\n",
      "         1.0       0.76      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 53/150, current lr=6.944284018723361e-06\n",
      "train loss: 0.002351 , accuracy: 97.19, time: 12.8484 min\n",
      "val loss: 0.025143 , accuracy: 86.01, time: 12.8484 min\n",
      "train_confusion_matrix\n",
      "[[296  13]\n",
      " [  5 326]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 54/150, current lr=6.597069817787193e-06\n",
      "train loss: 0.003926 , accuracy: 94.69, time: 13.0779 min\n",
      "val loss: 0.021609 , accuracy: 84.62, time: 13.0779 min\n",
      "train_confusion_matrix\n",
      "[[298  24]\n",
      " [ 10 308]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 55/150, current lr=6.267216326897833e-06\n",
      "train loss: 0.002207 , accuracy: 96.09, time: 13.3050 min\n",
      "val loss: 0.024030 , accuracy: 84.62, time: 13.3050 min\n",
      "train_confusion_matrix\n",
      "[[291  18]\n",
      " [  7 324]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [11 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88        92\n",
      "         1.0       0.78      0.78      0.78        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.83      0.83       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 56/150, current lr=5.953855510552941e-06\n",
      "train loss: 0.003667 , accuracy: 94.84, time: 13.5340 min\n",
      "val loss: 0.024021 , accuracy: 84.62, time: 13.5340 min\n",
      "train_confusion_matrix\n",
      "[[309  26]\n",
      " [  7 298]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 57/150, current lr=5.6561627350252934e-06\n",
      "train loss: 0.001659 , accuracy: 97.81, time: 13.7678 min\n",
      "val loss: 0.024038 , accuracy: 83.92, time: 13.7678 min\n",
      "train_confusion_matrix\n",
      "[[299  11]\n",
      " [  3 327]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 58/150, current lr=5.373354598274029e-06\n",
      "train loss: 0.002893 , accuracy: 95.78, time: 14.0050 min\n",
      "val loss: 0.025249 , accuracy: 82.52, time: 14.0050 min\n",
      "train_confusion_matrix\n",
      "[[310  21]\n",
      " [  6 303]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.80      0.86        92\n",
      "         1.0       0.71      0.86      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 59/150, current lr=5.104686868360327e-06\n",
      "train loss: 0.003045 , accuracy: 95.78, time: 14.2453 min\n",
      "val loss: 0.021461 , accuracy: 83.22, time: 14.2453 min\n",
      "train_confusion_matrix\n",
      "[[297  21]\n",
      " [  6 316]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86        92\n",
      "         1.0       0.71      0.88      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.84       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 60/150, current lr=4.84945252494231e-06\n",
      "train loss: 0.005926 , accuracy: 94.22, time: 14.4881 min\n",
      "val loss: 0.020433 , accuracy: 87.41, time: 14.4881 min\n",
      "train_confusion_matrix\n",
      "[[295  27]\n",
      " [ 10 308]]\n",
      "val_confustion_matrix\n",
      "[[82 10]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90        92\n",
      "         1.0       0.81      0.84      0.83        51\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.86      0.87      0.86       143\n",
      "weighted avg       0.88      0.87      0.87       143\n",
      "\n",
      "0.8741258741258742\n",
      "------------------------------\n",
      "Epoch 61/150, current lr=4.6069798986951945e-06\n",
      "train loss: 0.003510 , accuracy: 94.69, time: 14.7315 min\n",
      "val loss: 0.023487 , accuracy: 82.52, time: 14.7315 min\n",
      "train_confusion_matrix\n",
      "[[302  29]\n",
      " [  5 304]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.79      0.85        92\n",
      "         1.0       0.70      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 62/150, current lr=4.3766309037604346e-06\n",
      "train loss: 0.003223 , accuracy: 95.62, time: 14.9714 min\n",
      "val loss: 0.027654 , accuracy: 81.82, time: 14.9714 min\n",
      "train_confusion_matrix\n",
      "[[303  23]\n",
      " [  5 309]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.78      0.85        92\n",
      "         1.0       0.69      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 63/150, current lr=4.157799358572413e-06\n",
      "train loss: 0.002743 , accuracy: 96.09, time: 15.2224 min\n",
      "val loss: 0.021999 , accuracy: 85.31, time: 15.2224 min\n",
      "train_confusion_matrix\n",
      "[[302  21]\n",
      " [  4 313]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 64/150, current lr=3.949909390643792e-06\n",
      "train loss: 0.003106 , accuracy: 95.78, time: 15.4808 min\n",
      "val loss: 0.025064 , accuracy: 81.12, time: 15.4808 min\n",
      "train_confusion_matrix\n",
      "[[292  19]\n",
      " [  8 321]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.79      0.84        92\n",
      "         1.0       0.69      0.84      0.76        51\n",
      "\n",
      "    accuracy                           0.81       143\n",
      "   macro avg       0.80      0.82      0.80       143\n",
      "weighted avg       0.83      0.81      0.81       143\n",
      "\n",
      "0.8111888111888111\n",
      "------------------------------\n",
      "Epoch 65/150, current lr=3.7524139211116024e-06\n",
      "train loss: 0.003630 , accuracy: 95.00, time: 15.7291 min\n",
      "val loss: 0.022146 , accuracy: 83.92, time: 15.7291 min\n",
      "train_confusion_matrix\n",
      "[[293  26]\n",
      " [  6 315]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 66/150, current lr=3.564793225056022e-06\n",
      "train loss: 0.002863 , accuracy: 96.09, time: 15.9737 min\n",
      "val loss: 0.020755 , accuracy: 83.92, time: 15.9737 min\n",
      "train_confusion_matrix\n",
      "[[295  21]\n",
      " [  4 320]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 67/150, current lr=3.3865535638032207e-06\n",
      "train loss: 0.003301 , accuracy: 95.78, time: 16.2191 min\n",
      "val loss: 0.023767 , accuracy: 84.62, time: 16.2191 min\n",
      "train_confusion_matrix\n",
      "[[300  22]\n",
      " [  5 313]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 68/150, current lr=3.2172258856130596e-06\n",
      "train loss: 0.004287 , accuracy: 96.56, time: 16.4594 min\n",
      "val loss: 0.021921 , accuracy: 82.52, time: 16.4594 min\n",
      "train_confusion_matrix\n",
      "[[300  15]\n",
      " [  7 318]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86        92\n",
      "         1.0       0.72      0.84      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 69/150, current lr=3.0563645913324067e-06\n",
      "train loss: 0.004072 , accuracy: 93.59, time: 16.7006 min\n",
      "val loss: 0.023713 , accuracy: 83.92, time: 16.7006 min\n",
      "train_confusion_matrix\n",
      "[[301  32]\n",
      " [  9 298]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 70/150, current lr=2.903546361765786e-06\n",
      "train loss: 0.002414 , accuracy: 96.41, time: 16.9403 min\n",
      "val loss: 0.019883 , accuracy: 84.62, time: 16.9403 min\n",
      "train_confusion_matrix\n",
      "[[298  18]\n",
      " [  5 319]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 71/150, current lr=2.7583690436774965e-06\n",
      "train loss: 0.003921 , accuracy: 95.00, time: 17.1920 min\n",
      "val loss: 0.023223 , accuracy: 84.62, time: 17.1920 min\n",
      "train_confusion_matrix\n",
      "[[293  28]\n",
      " [  4 315]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.86      0.88        92\n",
      "         1.0       0.76      0.82      0.79        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.84      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 72/150, current lr=2.6204505914936218e-06\n",
      "train loss: 0.004328 , accuracy: 95.00, time: 17.4470 min\n",
      "val loss: 0.021954 , accuracy: 82.52, time: 17.4470 min\n",
      "train_confusion_matrix\n",
      "[[290  24]\n",
      " [  8 318]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.80      0.86        92\n",
      "         1.0       0.71      0.86      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 73/150, current lr=2.4894280619189404e-06\n",
      "train loss: 0.002498 , accuracy: 96.09, time: 17.6967 min\n",
      "val loss: 0.025111 , accuracy: 83.92, time: 17.6967 min\n",
      "train_confusion_matrix\n",
      "[[314  20]\n",
      " [  5 301]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 74/150, current lr=2.3649566588229932e-06\n",
      "train loss: 0.004288 , accuracy: 94.69, time: 17.9445 min\n",
      "val loss: 0.021432 , accuracy: 85.31, time: 17.9445 min\n",
      "train_confusion_matrix\n",
      "[[291  29]\n",
      " [  5 315]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.84      0.88        92\n",
      "         1.0       0.75      0.88      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.85       143\n",
      "weighted avg       0.86      0.85      0.86       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 75/150, current lr=2.2467088258818436e-06\n",
      "train loss: 0.002572 , accuracy: 96.72, time: 18.1893 min\n",
      "val loss: 0.023145 , accuracy: 84.62, time: 18.1893 min\n",
      "train_confusion_matrix\n",
      "[[303  17]\n",
      " [  4 316]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 76/150, current lr=2.1343733845877514e-06\n",
      "train loss: 0.004312 , accuracy: 95.47, time: 18.4151 min\n",
      "val loss: 0.020195 , accuracy: 84.62, time: 18.4151 min\n",
      "train_confusion_matrix\n",
      "[[310  23]\n",
      " [  6 301]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 77/150, current lr=2.027654715358364e-06\n",
      "train loss: 0.003113 , accuracy: 95.78, time: 18.6376 min\n",
      "val loss: 0.025541 , accuracy: 84.62, time: 18.6376 min\n",
      "train_confusion_matrix\n",
      "[[290  16]\n",
      " [ 11 323]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 78/150, current lr=1.9262719795904457e-06\n",
      "train loss: 0.003613 , accuracy: 93.59, time: 18.8613 min\n",
      "val loss: 0.020238 , accuracy: 85.31, time: 18.8613 min\n",
      "train_confusion_matrix\n",
      "[[293  29]\n",
      " [ 12 306]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88        92\n",
      "         1.0       0.76      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 79/150, current lr=1.8299583806109232e-06\n",
      "train loss: 0.004444 , accuracy: 94.84, time: 19.1032 min\n",
      "val loss: 0.022906 , accuracy: 83.92, time: 19.1032 min\n",
      "train_confusion_matrix\n",
      "[[288  23]\n",
      " [ 10 319]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 80/150, current lr=1.738460461580377e-06\n",
      "train loss: 0.003378 , accuracy: 94.22, time: 19.3394 min\n",
      "val loss: 0.023132 , accuracy: 81.82, time: 19.3394 min\n",
      "train_confusion_matrix\n",
      "[[303  33]\n",
      " [  4 300]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.79      0.85        92\n",
      "         1.0       0.70      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 81/150, current lr=1.651537438501358e-06\n",
      "train loss: 0.003088 , accuracy: 95.31, time: 19.5725 min\n",
      "val loss: 0.019591 , accuracy: 84.62, time: 19.5725 min\n",
      "train_confusion_matrix\n",
      "[[299  26]\n",
      " [  4 311]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88        92\n",
      "         1.0       0.75      0.86      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 82/150, current lr=1.5689605665762901e-06\n",
      "train loss: 0.003246 , accuracy: 95.31, time: 19.7919 min\n",
      "val loss: 0.023339 , accuracy: 81.82, time: 19.7919 min\n",
      "train_confusion_matrix\n",
      "[[289  22]\n",
      " [  8 321]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.78      0.85        92\n",
      "         1.0       0.69      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 83/150, current lr=1.4905125382474756e-06\n",
      "train loss: 0.003342 , accuracy: 95.94, time: 20.0179 min\n",
      "val loss: 0.026057 , accuracy: 85.31, time: 20.0179 min\n",
      "train_confusion_matrix\n",
      "[[287  20]\n",
      " [  6 327]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 84/150, current lr=1.4159869113351018e-06\n",
      "train loss: 0.002061 , accuracy: 95.94, time: 20.2529 min\n",
      "val loss: 0.021803 , accuracy: 86.01, time: 20.2529 min\n",
      "train_confusion_matrix\n",
      "[[281  24]\n",
      " [  2 333]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 85/150, current lr=1.3451875657683467e-06\n",
      "train loss: 0.002251 , accuracy: 95.94, time: 20.4853 min\n",
      "val loss: 0.022628 , accuracy: 86.71, time: 20.4854 min\n",
      "train_confusion_matrix\n",
      "[[287  21]\n",
      " [  5 327]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.87      0.89        92\n",
      "         1.0       0.79      0.86      0.82        51\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.85      0.87      0.86       143\n",
      "weighted avg       0.87      0.87      0.87       143\n",
      "\n",
      "0.8671328671328671\n",
      "------------------------------\n",
      "Epoch 86/150, current lr=1.2779281874799292e-06\n",
      "train loss: 0.003398 , accuracy: 94.38, time: 20.7312 min\n",
      "val loss: 0.030863 , accuracy: 85.31, time: 20.7312 min\n",
      "train_confusion_matrix\n",
      "[[289  31]\n",
      " [  5 315]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 87/150, current lr=1.2140317781059327e-06\n",
      "train loss: 0.002497 , accuracy: 96.09, time: 20.9871 min\n",
      "val loss: 0.028743 , accuracy: 83.22, time: 20.9871 min\n",
      "train_confusion_matrix\n",
      "[[296  20]\n",
      " [  5 319]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 88/150, current lr=1.153330189200636e-06\n",
      "train loss: 0.002951 , accuracy: 96.72, time: 21.2313 min\n",
      "val loss: 0.022353 , accuracy: 85.31, time: 21.2313 min\n",
      "train_confusion_matrix\n",
      "[[300  15]\n",
      " [  6 319]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.87      0.88        92\n",
      "         1.0       0.78      0.82      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 89/150, current lr=1.0956636797406041e-06\n",
      "train loss: 0.002566 , accuracy: 96.41, time: 21.4755 min\n",
      "val loss: 0.022359 , accuracy: 83.22, time: 21.4755 min\n",
      "train_confusion_matrix\n",
      "[[307  16]\n",
      " [  7 310]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86        92\n",
      "         1.0       0.72      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 90/150, current lr=1.0408804957535738e-06\n",
      "train loss: 0.004167 , accuracy: 93.75, time: 21.7189 min\n",
      "val loss: 0.022986 , accuracy: 83.92, time: 21.7189 min\n",
      "train_confusion_matrix\n",
      "[[305  35]\n",
      " [  5 295]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.82      0.87        92\n",
      "         1.0       0.73      0.88      0.80        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.83      0.85      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 91/150, current lr=9.88836470965895e-07\n",
      "train loss: 0.003015 , accuracy: 96.56, time: 21.9494 min\n",
      "val loss: 0.024539 , accuracy: 81.82, time: 21.9494 min\n",
      "train_confusion_matrix\n",
      "[[314  19]\n",
      " [  3 304]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.79      0.85        92\n",
      "         1.0       0.70      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 92/150, current lr=9.393946474176003e-07\n",
      "train loss: 0.002868 , accuracy: 95.78, time: 22.1910 min\n",
      "val loss: 0.023810 , accuracy: 82.52, time: 22.1910 min\n",
      "train_confusion_matrix\n",
      "[[307  24]\n",
      " [  3 306]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86        92\n",
      "         1.0       0.72      0.84      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 93/150, current lr=8.924249150467202e-07\n",
      "train loss: 0.004284 , accuracy: 93.59, time: 22.4337 min\n",
      "val loss: 0.026059 , accuracy: 82.52, time: 22.4337 min\n",
      "train_confusion_matrix\n",
      "[[296  33]\n",
      " [  8 303]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.79      0.85        92\n",
      "         1.0       0.70      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 94/150, current lr=8.478036692943841e-07\n",
      "train loss: 0.003424 , accuracy: 95.16, time: 22.6900 min\n",
      "val loss: 0.022981 , accuracy: 82.52, time: 22.6901 min\n",
      "train_confusion_matrix\n",
      "[[290  28]\n",
      " [  3 319]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.80      0.86        92\n",
      "         1.0       0.71      0.86      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 95/150, current lr=8.054134858296649e-07\n",
      "train loss: 0.002924 , accuracy: 95.78, time: 22.9504 min\n",
      "val loss: 0.024319 , accuracy: 81.12, time: 22.9504 min\n",
      "train_confusion_matrix\n",
      "[[311  24]\n",
      " [  3 302]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.78      0.84        92\n",
      "         1.0       0.69      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.81       143\n",
      "   macro avg       0.80      0.82      0.80       143\n",
      "weighted avg       0.83      0.81      0.81       143\n",
      "\n",
      "0.8111888111888111\n",
      "------------------------------\n",
      "Epoch 96/150, current lr=7.651428115381816e-07\n",
      "train loss: 0.002747 , accuracy: 95.94, time: 23.2257 min\n",
      "val loss: 0.022378 , accuracy: 83.22, time: 23.2257 min\n",
      "train_confusion_matrix\n",
      "[[316  23]\n",
      " [  3 298]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86        92\n",
      "         1.0       0.72      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 97/150, current lr=7.268856709612725e-07\n",
      "train loss: 0.003348 , accuracy: 95.78, time: 23.5060 min\n",
      "val loss: 0.022055 , accuracy: 84.62, time: 23.5060 min\n",
      "train_confusion_matrix\n",
      "[[296  22]\n",
      " [  5 317]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88        92\n",
      "         1.0       0.75      0.86      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 98/150, current lr=6.905413874132088e-07\n",
      "train loss: 0.004281 , accuracy: 95.31, time: 23.7646 min\n",
      "val loss: 0.021237 , accuracy: 84.62, time: 23.7646 min\n",
      "train_confusion_matrix\n",
      "[[294  19]\n",
      " [ 11 316]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 99/150, current lr=6.560143180425484e-07\n",
      "train loss: 0.003326 , accuracy: 95.78, time: 24.0186 min\n",
      "val loss: 0.021734 , accuracy: 83.92, time: 24.0186 min\n",
      "train_confusion_matrix\n",
      "[[320  22]\n",
      " [  5 293]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 5 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.80      0.87        92\n",
      "         1.0       0.72      0.90      0.80        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.83      0.85      0.83       143\n",
      "weighted avg       0.86      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 100/150, current lr=6.232136021404209e-07\n",
      "train loss: 0.003109 , accuracy: 96.09, time: 24.2789 min\n",
      "val loss: 0.020926 , accuracy: 85.31, time: 24.2789 min\n",
      "train_confusion_matrix\n",
      "[[299  16]\n",
      " [  9 316]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88        92\n",
      "         1.0       0.76      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 101/150, current lr=5.920529220333999e-07\n",
      "train loss: 0.002460 , accuracy: 96.09, time: 24.5285 min\n",
      "val loss: 0.021100 , accuracy: 83.22, time: 24.5285 min\n",
      "train_confusion_matrix\n",
      "[[291  19]\n",
      " [  6 324]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86        92\n",
      "         1.0       0.72      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 102/150, current lr=5.624502759317298e-07\n",
      "train loss: 0.003718 , accuracy: 95.62, time: 24.7798 min\n",
      "val loss: 0.020838 , accuracy: 85.31, time: 24.7798 min\n",
      "train_confusion_matrix\n",
      "[[295  19]\n",
      " [  9 317]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 103/150, current lr=5.343277621351433e-07\n",
      "train loss: 0.003110 , accuracy: 95.47, time: 25.0371 min\n",
      "val loss: 0.024860 , accuracy: 83.22, time: 25.0371 min\n",
      "train_confusion_matrix\n",
      "[[282  19]\n",
      " [ 10 329]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86        92\n",
      "         1.0       0.72      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 104/150, current lr=5.076113740283861e-07\n",
      "train loss: 0.002726 , accuracy: 95.62, time: 25.2891 min\n",
      "val loss: 0.023886 , accuracy: 83.92, time: 25.2892 min\n",
      "train_confusion_matrix\n",
      "[[305  24]\n",
      " [  4 307]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 105/150, current lr=4.822308053269667e-07\n",
      "train loss: 0.005117 , accuracy: 95.16, time: 25.5404 min\n",
      "val loss: 0.019800 , accuracy: 83.22, time: 25.5404 min\n",
      "train_confusion_matrix\n",
      "[[278  19]\n",
      " [ 12 331]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 106/150, current lr=4.581192650606184e-07\n",
      "train loss: 0.002610 , accuracy: 96.41, time: 25.7982 min\n",
      "val loss: 0.025593 , accuracy: 83.22, time: 25.7982 min\n",
      "train_confusion_matrix\n",
      "[[304  21]\n",
      " [  2 313]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.82      0.86        92\n",
      "         1.0       0.72      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 107/150, current lr=4.3521330180758747e-07\n",
      "train loss: 0.002222 , accuracy: 95.94, time: 26.0575 min\n",
      "val loss: 0.021382 , accuracy: 86.71, time: 26.0575 min\n",
      "train_confusion_matrix\n",
      "[[297  22]\n",
      " [  4 317]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.90        92\n",
      "         1.0       0.80      0.84      0.82        51\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.85      0.86      0.86       143\n",
      "weighted avg       0.87      0.87      0.87       143\n",
      "\n",
      "0.8671328671328671\n",
      "------------------------------\n",
      "Epoch 108/150, current lr=4.1345263671720807e-07\n",
      "train loss: 0.002926 , accuracy: 96.09, time: 26.3159 min\n",
      "val loss: 0.024382 , accuracy: 84.62, time: 26.3159 min\n",
      "train_confusion_matrix\n",
      "[[301  16]\n",
      " [  9 314]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 109/150, current lr=3.9278000488134764e-07\n",
      "train loss: 0.003566 , accuracy: 95.62, time: 26.5803 min\n",
      "val loss: 0.023499 , accuracy: 84.62, time: 26.5803 min\n",
      "train_confusion_matrix\n",
      "[[300  23]\n",
      " [  5 312]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 110/150, current lr=3.7314100463728023e-07\n",
      "train loss: 0.004461 , accuracy: 93.91, time: 26.8349 min\n",
      "val loss: 0.021058 , accuracy: 86.01, time: 26.8349 min\n",
      "train_confusion_matrix\n",
      "[[277  25]\n",
      " [ 14 324]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 111/150, current lr=3.544839544054162e-07\n",
      "train loss: 0.003684 , accuracy: 95.00, time: 27.0930 min\n",
      "val loss: 0.023006 , accuracy: 86.01, time: 27.0930 min\n",
      "train_confusion_matrix\n",
      "[[284  25]\n",
      " [  7 324]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.88      0.89        92\n",
      "         1.0       0.79      0.82      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.85      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 112/150, current lr=3.367597566851454e-07\n",
      "train loss: 0.002561 , accuracy: 96.56, time: 27.3638 min\n",
      "val loss: 0.024394 , accuracy: 86.01, time: 27.3638 min\n",
      "train_confusion_matrix\n",
      "[[281  14]\n",
      " [  8 337]]\n",
      "val_confustion_matrix\n",
      "[[82 10]\n",
      " [10 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89        92\n",
      "         1.0       0.80      0.80      0.80        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.85      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 113/150, current lr=3.199217688508881e-07\n",
      "train loss: 0.003039 , accuracy: 96.25, time: 27.6214 min\n",
      "val loss: 0.024322 , accuracy: 86.01, time: 27.6214 min\n",
      "train_confusion_matrix\n",
      "[[298  19]\n",
      " [  5 318]]\n",
      "val_confustion_matrix\n",
      "[[80 12]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.87      0.89        92\n",
      "         1.0       0.78      0.84      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.86      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 114/150, current lr=3.0392568040834367e-07\n",
      "train loss: 0.002718 , accuracy: 96.56, time: 27.8632 min\n",
      "val loss: 0.025137 , accuracy: 83.22, time: 27.8632 min\n",
      "train_confusion_matrix\n",
      "[[298  15]\n",
      " [  7 320]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 115/150, current lr=2.887293963879265e-07\n",
      "train loss: 0.005016 , accuracy: 93.44, time: 28.0936 min\n",
      "val loss: 0.022688 , accuracy: 82.52, time: 28.0936 min\n",
      "train_confusion_matrix\n",
      "[[296  34]\n",
      " [  8 302]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 5 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.78      0.85        92\n",
      "         1.0       0.70      0.90      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 116/150, current lr=2.7429292656853013e-07\n",
      "train loss: 0.002863 , accuracy: 95.16, time: 28.3310 min\n",
      "val loss: 0.023377 , accuracy: 85.31, time: 28.3310 min\n",
      "train_confusion_matrix\n",
      "[[304  23]\n",
      " [  8 305]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88        92\n",
      "         1.0       0.76      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 117/150, current lr=2.605782802401036e-07\n",
      "train loss: 0.002448 , accuracy: 95.47, time: 28.5670 min\n",
      "val loss: 0.022837 , accuracy: 83.92, time: 28.5670 min\n",
      "train_confusion_matrix\n",
      "[[311  25]\n",
      " [  4 300]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 118/150, current lr=2.475493662280984e-07\n",
      "train loss: 0.001996 , accuracy: 96.41, time: 28.8081 min\n",
      "val loss: 0.025294 , accuracy: 85.31, time: 28.8081 min\n",
      "train_confusion_matrix\n",
      "[[304  17]\n",
      " [  6 313]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 119/150, current lr=2.3517189791669347e-07\n",
      "train loss: 0.003752 , accuracy: 95.78, time: 29.0522 min\n",
      "val loss: 0.024754 , accuracy: 81.82, time: 29.0522 min\n",
      "train_confusion_matrix\n",
      "[[314  19]\n",
      " [  8 299]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.79      0.85        92\n",
      "         1.0       0.70      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 120/150, current lr=2.234133030208588e-07\n",
      "train loss: 0.002573 , accuracy: 96.72, time: 29.3033 min\n",
      "val loss: 0.025797 , accuracy: 86.01, time: 29.3033 min\n",
      "train_confusion_matrix\n",
      "[[292  14]\n",
      " [  7 327]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [ 9 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.88      0.89        92\n",
      "         1.0       0.79      0.82      0.81        51\n",
      "\n",
      "    accuracy                           0.86       143\n",
      "   macro avg       0.85      0.85      0.85       143\n",
      "weighted avg       0.86      0.86      0.86       143\n",
      "\n",
      "0.8601398601398601\n",
      "------------------------------\n",
      "Epoch 121/150, current lr=2.1224263786981584e-07\n",
      "train loss: 0.002612 , accuracy: 95.00, time: 29.5477 min\n",
      "val loss: 0.022670 , accuracy: 84.62, time: 29.5478 min\n",
      "train_confusion_matrix\n",
      "[[292  28]\n",
      " [  4 316]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88        92\n",
      "         1.0       0.75      0.86      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 122/150, current lr=2.0163050597632503e-07\n",
      "train loss: 0.004698 , accuracy: 93.28, time: 29.7918 min\n",
      "val loss: 0.021769 , accuracy: 83.92, time: 29.7918 min\n",
      "train_confusion_matrix\n",
      "[[295  37]\n",
      " [  6 302]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 123/150, current lr=1.9154898067750878e-07\n",
      "train loss: 0.003816 , accuracy: 95.78, time: 30.0443 min\n",
      "val loss: 0.023986 , accuracy: 85.31, time: 30.0443 min\n",
      "train_confusion_matrix\n",
      "[[282  19]\n",
      " [  8 331]]\n",
      "val_confustion_matrix\n",
      "[[79 13]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.86      0.88        92\n",
      "         1.0       0.77      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 124/150, current lr=1.8197153164363334e-07\n",
      "train loss: 0.003044 , accuracy: 95.62, time: 30.2876 min\n",
      "val loss: 0.023107 , accuracy: 83.22, time: 30.2876 min\n",
      "train_confusion_matrix\n",
      "[[297  22]\n",
      " [  6 315]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 125/150, current lr=1.7287295506145167e-07\n",
      "train loss: 0.002598 , accuracy: 95.78, time: 30.5246 min\n",
      "val loss: 0.020488 , accuracy: 83.22, time: 30.5246 min\n",
      "train_confusion_matrix\n",
      "[[305  22]\n",
      " [  5 308]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 126/150, current lr=1.6422930730837908e-07\n",
      "train loss: 0.003215 , accuracy: 95.47, time: 30.7724 min\n",
      "val loss: 0.023177 , accuracy: 83.92, time: 30.7724 min\n",
      "train_confusion_matrix\n",
      "[[291  17]\n",
      " [ 12 320]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 127/150, current lr=1.560178419429601e-07\n",
      "train loss: 0.002755 , accuracy: 95.94, time: 31.0221 min\n",
      "val loss: 0.023874 , accuracy: 81.82, time: 31.0221 min\n",
      "train_confusion_matrix\n",
      "[[309  23]\n",
      " [  3 305]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.80      0.85        92\n",
      "         1.0       0.70      0.84      0.77        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.80      0.82      0.81       143\n",
      "weighted avg       0.83      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 128/150, current lr=1.482169498458121e-07\n",
      "train loss: 0.004127 , accuracy: 94.22, time: 31.2743 min\n",
      "val loss: 0.022011 , accuracy: 82.52, time: 31.2743 min\n",
      "train_confusion_matrix\n",
      "[[299  29]\n",
      " [  8 304]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.79      0.85        92\n",
      "         1.0       0.70      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 129/150, current lr=1.4080610235352148e-07\n",
      "train loss: 0.002861 , accuracy: 95.78, time: 31.5175 min\n",
      "val loss: 0.023383 , accuracy: 83.22, time: 31.5175 min\n",
      "train_confusion_matrix\n",
      "[[297  22]\n",
      " [  5 316]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 130/150, current lr=1.337657972358454e-07\n",
      "train loss: 0.003119 , accuracy: 95.31, time: 31.7543 min\n",
      "val loss: 0.022100 , accuracy: 84.62, time: 31.7543 min\n",
      "train_confusion_matrix\n",
      "[[313  25]\n",
      " [  5 297]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.84      0.88        92\n",
      "         1.0       0.75      0.86      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 131/150, current lr=1.2707750737405312e-07\n",
      "train loss: 0.003627 , accuracy: 95.62, time: 31.9919 min\n",
      "val loss: 0.021094 , accuracy: 85.31, time: 31.9919 min\n",
      "train_confusion_matrix\n",
      "[[311  24]\n",
      " [  4 301]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.88        92\n",
      "         1.0       0.76      0.86      0.81        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.84      0.86      0.84       143\n",
      "weighted avg       0.86      0.85      0.85       143\n",
      "\n",
      "0.8531468531468531\n",
      "------------------------------\n",
      "Epoch 132/150, current lr=1.2072363200535045e-07\n",
      "train loss: 0.003123 , accuracy: 96.25, time: 32.2365 min\n",
      "val loss: 0.024004 , accuracy: 83.92, time: 32.2366 min\n",
      "train_confusion_matrix\n",
      "[[288  17]\n",
      " [  7 328]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 133/150, current lr=1.1468745040508292e-07\n",
      "train loss: 0.003846 , accuracy: 95.31, time: 32.4797 min\n",
      "val loss: 0.024344 , accuracy: 84.62, time: 32.4797 min\n",
      "train_confusion_matrix\n",
      "[[308  25]\n",
      " [  5 302]]\n",
      "val_confustion_matrix\n",
      "[[78 14]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.85      0.88        92\n",
      "         1.0       0.75      0.84      0.80        51\n",
      "\n",
      "    accuracy                           0.85       143\n",
      "   macro avg       0.83      0.85      0.84       143\n",
      "weighted avg       0.85      0.85      0.85       143\n",
      "\n",
      "0.8461538461538461\n",
      "------------------------------\n",
      "Epoch 134/150, current lr=1.0895307788482877e-07\n",
      "train loss: 0.002335 , accuracy: 96.09, time: 32.7246 min\n",
      "val loss: 0.023519 , accuracy: 83.22, time: 32.7246 min\n",
      "train_confusion_matrix\n",
      "[[294  18]\n",
      " [  7 321]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 135/150, current lr=1.0350542399058734e-07\n",
      "train loss: 0.002826 , accuracy: 96.25, time: 32.9733 min\n",
      "val loss: 0.022557 , accuracy: 81.82, time: 32.9733 min\n",
      "train_confusion_matrix\n",
      "[[302  20]\n",
      " [  4 314]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.78      0.85        92\n",
      "         1.0       0.69      0.88      0.78        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 136/150, current lr=9.833015279105797e-08\n",
      "train loss: 0.004723 , accuracy: 94.38, time: 33.2310 min\n",
      "val loss: 0.023271 , accuracy: 83.22, time: 33.2310 min\n",
      "train_confusion_matrix\n",
      "[[301  32]\n",
      " [  4 303]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.83      0.86        92\n",
      "         1.0       0.73      0.84      0.78        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 137/150, current lr=9.341364515150507e-08\n",
      "train loss: 0.002879 , accuracy: 96.25, time: 33.4925 min\n",
      "val loss: 0.023579 , accuracy: 87.41, time: 33.4925 min\n",
      "train_confusion_matrix\n",
      "[[288  21]\n",
      " [  3 328]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90        92\n",
      "         1.0       0.80      0.86      0.83        51\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.86      0.87      0.87       143\n",
      "weighted avg       0.88      0.87      0.88       143\n",
      "\n",
      "0.8741258741258742\n",
      "------------------------------\n",
      "Epoch 138/150, current lr=8.874296289392981e-08\n",
      "train loss: 0.002669 , accuracy: 96.25, time: 33.7395 min\n",
      "val loss: 0.021412 , accuracy: 83.92, time: 33.7395 min\n",
      "train_confusion_matrix\n",
      "[[307  20]\n",
      " [  4 309]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 139/150, current lr=8.430581474923332e-08\n",
      "train loss: 0.002144 , accuracy: 96.41, time: 33.9814 min\n",
      "val loss: 0.020978 , accuracy: 83.92, time: 33.9814 min\n",
      "train_confusion_matrix\n",
      "[[299  20]\n",
      " [  3 318]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.82      0.87        92\n",
      "         1.0       0.73      0.88      0.80        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.83      0.85      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 140/150, current lr=8.009052401177165e-08\n",
      "train loss: 0.002878 , accuracy: 94.84, time: 34.2211 min\n",
      "val loss: 0.027146 , accuracy: 81.12, time: 34.2211 min\n",
      "train_confusion_matrix\n",
      "[[297  28]\n",
      " [  5 310]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.78      0.84        92\n",
      "         1.0       0.69      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.81       143\n",
      "   macro avg       0.80      0.82      0.80       143\n",
      "weighted avg       0.83      0.81      0.81       143\n",
      "\n",
      "0.8111888111888111\n",
      "------------------------------\n",
      "Epoch 141/150, current lr=7.608599781118306e-08\n",
      "train loss: 0.003372 , accuracy: 94.06, time: 34.4686 min\n",
      "val loss: 0.024129 , accuracy: 83.22, time: 34.4686 min\n",
      "train_confusion_matrix\n",
      "[[293  31]\n",
      " [  7 309]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86        92\n",
      "         1.0       0.71      0.88      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.84       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 142/150, current lr=7.22816979206239e-08\n",
      "train loss: 0.002322 , accuracy: 96.09, time: 34.7253 min\n",
      "val loss: 0.026762 , accuracy: 82.52, time: 34.7253 min\n",
      "train_confusion_matrix\n",
      "[[312  23]\n",
      " [  2 303]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86        92\n",
      "         1.0       0.72      0.84      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 143/150, current lr=6.86676130245927e-08\n",
      "train loss: 0.002868 , accuracy: 96.09, time: 34.9840 min\n",
      "val loss: 0.022083 , accuracy: 82.52, time: 34.9840 min\n",
      "train_confusion_matrix\n",
      "[[303  21]\n",
      " [  4 312]]\n",
      "val_confustion_matrix\n",
      "[[75 17]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86        92\n",
      "         1.0       0.72      0.84      0.77        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.81      0.83      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "0.8251748251748252\n",
      "------------------------------\n",
      "Epoch 144/150, current lr=6.523423237336307e-08\n",
      "train loss: 0.004174 , accuracy: 94.06, time: 35.2469 min\n",
      "val loss: 0.024442 , accuracy: 83.92, time: 35.2469 min\n",
      "train_confusion_matrix\n",
      "[[285  29]\n",
      " [  9 317]]\n",
      "val_confustion_matrix\n",
      "[[77 15]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.74      0.84      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 145/150, current lr=6.197252075469491e-08\n",
      "train loss: 0.002765 , accuracy: 95.31, time: 35.5114 min\n",
      "val loss: 0.024926 , accuracy: 83.22, time: 35.5114 min\n",
      "train_confusion_matrix\n",
      "[[305  19]\n",
      " [ 11 305]]\n",
      "val_confustion_matrix\n",
      "[[74 18]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86        92\n",
      "         1.0       0.71      0.88      0.79        51\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.82      0.84      0.82       143\n",
      "weighted avg       0.85      0.83      0.84       143\n",
      "\n",
      "0.8321678321678322\n",
      "------------------------------\n",
      "Epoch 146/150, current lr=5.887389471696016e-08\n",
      "train loss: 0.002749 , accuracy: 95.94, time: 35.7800 min\n",
      "val loss: 0.021720 , accuracy: 81.12, time: 35.7800 min\n",
      "train_confusion_matrix\n",
      "[[301  19]\n",
      " [  7 313]]\n",
      "val_confustion_matrix\n",
      "[[72 20]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.78      0.84        92\n",
      "         1.0       0.69      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.81       143\n",
      "   macro avg       0.80      0.82      0.80       143\n",
      "weighted avg       0.83      0.81      0.81       143\n",
      "\n",
      "0.8111888111888111\n",
      "------------------------------\n",
      "Epoch 147/150, current lr=5.593019998111215e-08\n",
      "train loss: 0.003269 , accuracy: 94.38, time: 36.0414 min\n",
      "val loss: 0.024438 , accuracy: 81.82, time: 36.0414 min\n",
      "train_confusion_matrix\n",
      "[[304  31]\n",
      " [  5 300]]\n",
      "val_confustion_matrix\n",
      "[[73 19]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.79      0.85        92\n",
      "         1.0       0.70      0.86      0.77        51\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.83      0.81       143\n",
      "weighted avg       0.84      0.82      0.82       143\n",
      "\n",
      "0.8181818181818182\n",
      "------------------------------\n",
      "Epoch 148/150, current lr=5.313368998205654e-08\n",
      "train loss: 0.002729 , accuracy: 95.31, time: 36.3118 min\n",
      "val loss: 0.021910 , accuracy: 83.92, time: 36.3118 min\n",
      "train_confusion_matrix\n",
      "[[301  27]\n",
      " [  3 309]]\n",
      "val_confustion_matrix\n",
      "[[76 16]\n",
      " [ 7 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87        92\n",
      "         1.0       0.73      0.86      0.79        51\n",
      "\n",
      "    accuracy                           0.84       143\n",
      "   macro avg       0.82      0.84      0.83       143\n",
      "weighted avg       0.85      0.84      0.84       143\n",
      "\n",
      "0.8391608391608392\n",
      "------------------------------\n",
      "Epoch 149/150, current lr=5.047700548295371e-08\n",
      "train loss: 0.003903 , accuracy: 94.69, time: 36.5716 min\n",
      "val loss: 0.022616 , accuracy: 79.02, time: 36.5716 min\n",
      "train_confusion_matrix\n",
      "[[303  32]\n",
      " [  2 303]]\n",
      "val_confustion_matrix\n",
      "[[68 24]\n",
      " [ 6 45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.74      0.82        92\n",
      "         1.0       0.65      0.88      0.75        51\n",
      "\n",
      "    accuracy                           0.79       143\n",
      "   macro avg       0.79      0.81      0.78       143\n",
      "weighted avg       0.82      0.79      0.79       143\n",
      "\n",
      "0.7902097902097902\n",
      "------------------------------\n",
      "Epoch 150/150, current lr=4.795315520880602e-08\n",
      "train loss: 0.003510 , accuracy: 95.62, time: 36.8407 min\n",
      "val loss: 0.023598 , accuracy: 86.71, time: 36.8407 min\n",
      "train_confusion_matrix\n",
      "[[282  17]\n",
      " [ 11 330]]\n",
      "val_confustion_matrix\n",
      "[[81 11]\n",
      " [ 8 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.90        92\n",
      "         1.0       0.80      0.84      0.82        51\n",
      "\n",
      "    accuracy                           0.87       143\n",
      "   macro avg       0.85      0.86      0.86       143\n",
      "weighted avg       0.87      0.87      0.87       143\n",
      "\n",
      "0.8671328671328671\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97ff550f-f1e9-4b63-8f51-9bda39e1de24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'loss')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = metric_hist['train']\n",
    "val_accuracy = metric_hist['val'] \n",
    "\n",
    "loss = loss_hist['train'] \n",
    "val_loss = loss_hist['val']\n",
    "\n",
    "epochs = range(len(loss_hist['train']))\n",
    "\n",
    "plt.plot(epochs, accuracy, label=\"train\") \n",
    "plt.plot(epochs, val_accuracy, label=\"val\") \n",
    "plt.legend() \n",
    "plt.title('accuracy') \n",
    "\n",
    "plt.figure() \n",
    "plt.plot(epochs, loss, label=\"train\")\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.plot(epochs, val_loss, label=\"val\") \n",
    "plt.xlabel('epochs')\n",
    "plt.legend() \n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f854e6ce-79e8-49b2-ac61-777ea4b98fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'seresnet50(b=16,Adam,Focal_alpha(0.75),WRS,sche,seed,7)_weights_pt'\n",
    "model_path = '/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/weights_file/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b4aa58d-72b3-4ce5-b57a-bb6fc7894a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = seresnet50_pretrained.to(device)\n",
    "model.load_state_dict(torch.load(model_path + model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967d057-2902-4214-bf3d-73aaac358b91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# output = model(input_data)\n",
    "model.eval()  \n",
    "\n",
    "test_accuracy = 0.0\n",
    "running_accuracy = 0.0\n",
    "len_dataset = len(test_dataloader.dataset)\n",
    "pred = []\n",
    "label = []\n",
    "outputs = []\n",
    "incorrect_normal_list = []\n",
    "incorrect_abnormal_list = []\n",
    "\n",
    "# valid data\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        \n",
    "        inputs = data['img']\n",
    "        labels = data['label']\n",
    "        idx = data['filename']\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device, dtype = torch.float32)\n",
    "        print(model(inputs))\n",
    "        \n",
    "        output = torch.squeeze(model(inputs))\n",
    "        output_sig = torch.sigmoid(output)\n",
    "        outputs.append(output_sig.cpu())\n",
    "        y_pred = output_sig.cpu()\n",
    "        y_pred[y_pred >= 0.5] = 1\n",
    "        y_pred[y_pred < 0.5] = 0\n",
    "        \n",
    "        if y_pred != labels.cpu():\n",
    "            if labels.cpu() == 1:\n",
    "                incorrect_abnormal_list.append(idx)\n",
    "            else:\n",
    "                incorrect_normal_list.append(idx)\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        y_pred_ = y_pred.detach().cpu().numpy().tolist()\n",
    "        print(y_pred_)\n",
    "        \n",
    "        correct_num = y_pred.eq(labels.cpu()).int().sum()\n",
    "        running_accuracy += correct_num\n",
    "        print(correct_num)\n",
    "        \n",
    "        labels_numpy = labels.detach().cpu().numpy().tolist()\n",
    "        print(labels_numpy)\n",
    "        \n",
    "        \n",
    "        pred.append(y_pred_)\n",
    "        label.append(labels_numpy)\n",
    "        \n",
    "#         print(confusion_matrix(y_pred,labels_numpy))\n",
    "#         print(classification_report(y_pred,labels_numpy))\n",
    "#         print(accuracy_score(y_pred,labels_numpy))\n",
    "\n",
    "test_accuracy = running_accuracy / len_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6b7f664-bf7b-459e-9ea8-565b0dfbbbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.374231, sensitivity = 0.935, specificity = 0.804, J=0.739\n",
      "[[77 15]\n",
      " [ 8 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.84      0.87        92\n",
      "         1.0       0.72      0.83      0.77        46\n",
      "\n",
      "    accuracy                           0.83       138\n",
      "   macro avg       0.81      0.83      0.82       138\n",
      "weighted avg       0.84      0.83      0.84       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from numpy import argmax\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(label, outputs)\n",
    "\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print('Best Threshold=%f, sensitivity = %.3f, specificity = %.3f, J=%.3f' % (best_thresh, tpr[ix], 1-fpr[ix], J[ix]))\n",
    "\n",
    "print(confusion_matrix(label,pred))\n",
    "print(classification_report(label,pred))\n",
    "cm = confusion_matrix(label,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0d49e13-7386-4c6c-8ca0-e34b7d53eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#plot roc and best threshold\n",
    "sens, spec = tpr[ix], 1-fpr[ix]\n",
    "# plot the roc curve for the model\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1], [0,1], linestyle='--', markersize=0.01, color='black')\n",
    "plt.plot(fpr, tpr, marker='.', color='black', markersize=0.05, label=\"Classifier AUC = %.3f\" % roc_auc_score(label, pred))\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='+', s=100, color='r', \n",
    "            label='Best threshold = %.3f, \\nSensitivity = %.3f, \\nSpecificity = %.3f' % (best_thresh, sens, spec))\n",
    "\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2846b0ce-173e-47f7-b85a-eb8225de3b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f18c8260e48>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# 라벨 설정\n",
    "label_name = ['Normal', 'Abnormal'] \n",
    "disp = ConfusionMatrixDisplay(cm, # 분류 모델\n",
    "                             display_labels=label_name, # 표에 표시할 labels\n",
    "                             ) # 'true', 'pred', 'all' 중에서 지정 가능. default=None\n",
    "disp.plot(cmap = plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455d58d-c445-4161-adbc-4e1d085b062c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
