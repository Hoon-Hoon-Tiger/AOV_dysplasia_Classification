{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1334e3eb-6a25-4141-a350-c4698cbb8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,plot_confusion_matrix\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90915749-bd87-498a-9649-8f5352a6c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed = 42):\n",
    "    random.seed(seed) # python random seed 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # os 자체의 seed 고정\n",
    "    np.random.seed(seed) # numpy seed 고정 \n",
    "    torch.manual_seed(seed) # torch seed 고정\n",
    "    torch.cuda.manual_seed(seed) # cudnn seed 고정\n",
    "    torch.backends.cudnn.deterministic = True # cudnn seed 고정(nn.Conv2d)\n",
    "    torch.backends.cudnn.benchmark = False # CUDA 내부 연산에서 가장 빠른 알고리즘을 찾아 수행\n",
    "\n",
    "## DataLoader worker에 대한 seed 설정\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39484847-020b-4a6f-975b-76a1d858b37d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Load(ResNet50(pretrained O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13c3db4-f528-4605-b58f-e403412538fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (se): SEModule(\n",
      "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (gate): Sigmoid()\n",
      "      )\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "import timm\n",
    "# m = timm.create_model('seresnet50', pretrained=True)\n",
    "\n",
    "seresnet50_pretrained = timm.create_model('seresnet50', pretrained=True)\n",
    "print(seresnet50_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf6d765-e9d5-48e8-95ef-ac9678762998",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 1\n",
    "num_features = seresnet50_pretrained.fc.in_features\n",
    "seresnet50_pretrained.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "seresnet50_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980bb983-a862-4697-bba7-a14d1e715e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu?  True\n",
      "Current gpu:  0\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "tensor([[-0.1496],\n",
      "        [ 0.0145],\n",
      "        [-0.2150]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "print('gpu? ', torch.cuda.is_available())\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print('Current gpu: ', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')\n",
    "    \n",
    "model = seresnet50_pretrained.to(device)\n",
    "x = torch.randn(3, 3, 224, 224).to(device)\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9955aef1-cbaa-4ead-a1a4-61ffb84fe8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'seresnet50(b=16,Adam,Focal_alpha(0.75),WRS,sche,seed)_weights_pt'\n",
    "model_path = '/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/weights_file/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802b8214-935b-46b9-ae13-1c153256cacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = seresnet50_pretrained.to(device)\n",
    "model.load_state_dict(torch.load(model_path + model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11562fdb-36a2-4d06-8ce7-8c14e45756e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad_CAM_code'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5122258-3647-4e4f-8158-ad6a9cbcaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 저장 위치:  /mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad-CAM_results/Grad-CAM_results(seResnet_Focal(0.75)_WRS_sch_validation)\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "# current_time = datetime.datetime.now() + datetime.timedelta(hours= 9)\n",
    "# current_time = current_time.strftime('%Y-%m-%d-%H:%M')\n",
    "\n",
    "\n",
    "saved_loc = os.path.join('/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad-CAM_results/Grad-CAM_results(seResnet_Focal(0.75)_WRS_sch_validation)', )\n",
    "if os.path.exists(saved_loc):\n",
    "    shutil.rmtree(saved_loc)\n",
    "os.mkdir(saved_loc)\n",
    "\n",
    "print(\"결과 저장 위치: \", saved_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f2cc1-104f-4bdf-9eae-1378182796eb",
   "metadata": {},
   "source": [
    "## test dataset & test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9052ec3a-63d5-434e-86fc-d7e56b63deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_path = '/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3/normal_train_v3/*.jpg'\n",
    "train_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3/abnormal_train_v3/*.jpg'\n",
    "valid_normal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3/normal_val_v3/*.jpg'\n",
    "valid_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3/abnormal_val_v3/*.jpg'\n",
    "test_normal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3/normal_test_v3/*.jpg'\n",
    "test_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v3/data_v3/abnormal_test_v3/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd0baa95-76b5-499c-ae50-2a40d9632742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_normal : 472\n",
      "val_normal : 52\n",
      "test_normal : 66\n",
      "------------------------------------\n",
      "train_abnormal : 259\n",
      "val_abnormal : 33\n",
      "test_abnormal : 39\n"
     ]
    }
   ],
   "source": [
    "train_normal_glob = glob(train_normal_path)\n",
    "train_abnormal_glob = glob(train_abnormal_path)\n",
    "val_normal_glob = glob(valid_normal_path)\n",
    "val_abnormal_glob = glob(valid_abnormal_path)\n",
    "test_normal_glob = glob(test_normal_path)\n",
    "test_abnormal_glob = glob(test_abnormal_path)\n",
    "\n",
    "print('train_normal :', len(train_normal_glob))\n",
    "print('val_normal :', len(val_normal_glob))\n",
    "print('test_normal :', len(test_normal_glob))\n",
    "print('------------------------------------')\n",
    "print('train_abnormal :', len(train_abnormal_glob))\n",
    "print('val_abnormal :', len(val_abnormal_glob))\n",
    "print('test_abnormal :', len(test_abnormal_glob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f42d6c8b-427c-4346-8b62-d6719ccec9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aov_Dysplasia_dataset(Dataset):\n",
    "    def __init__(self, normal_path, abnormal_path, transform=None):\n",
    "        #생성자, 데이터를 전처리 \n",
    "        self.normal_path_list = glob(normal_path)\n",
    "        self.abnormal_path_list = glob(abnormal_path)\n",
    "        print(len(self.normal_path_list))\n",
    "#         self.mode = mode \n",
    "    \n",
    "#         label = np.array([[0, 1], [1, 0]], dtype=np.float32)\n",
    "        \n",
    "#         self.label_list = []\n",
    "#         for i in self.normal_path_list:\n",
    "#             self.label_list.append(label[0])\n",
    "            \n",
    "#         for i in self.abnormal_path_list:\n",
    "#             self.label_list.append(label[1])\n",
    "            \n",
    "        label_policy = {\n",
    "            'normal': 0, \n",
    "            'abnormal': 1\n",
    "        }\n",
    "    \n",
    "        self.label_list= []\n",
    "        \n",
    "        for i in self.normal_path_list:\n",
    "            self.label_list.append(label_policy[\"normal\"])\n",
    "            \n",
    "        for i in self.abnormal_path_list:\n",
    "            self.label_list.append(label_policy[\"abnormal\"])\n",
    "        \n",
    "        self.total_img_path_list = self.normal_path_list + self.abnormal_path_list\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.total_img_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = cv2.imread(self.total_img_path_list[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # img = np.array(img, dtype=np.float32)\n",
    "        #들어오는 이미지의 컬러 형태가 BGR인지 RGB인지 모르기때문에 변형\n",
    "\n",
    "        \n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image'] \n",
    "            img = torch.tensor(np.array(img), dtype=torch.float32)\n",
    "            # img = torch.FloatTensor(img)\n",
    "            img = (img - torch.min(img)) / (torch.max(img)-torch.min(img))\n",
    "            \n",
    "            return {'img': img, 'label': label, 'filename': self.total_img_path_list[idx]}\n",
    "        \n",
    "        else:\n",
    "            # img = transformed['image']\n",
    "            img = torch.tensor(np.array(img), dtype=torch.float32)\n",
    "            # img = torch.FloatTensor(img)\n",
    "            img = (img - torch.min(img)) / (torch.max(img)-torch.min(img))\n",
    "            return{'img': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f848d606-c2f5-4af8-b4de-0af8e7ae6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://albumentations.ai/docs/api_reference/augmentations/transforms/\n",
    "import albumentations as A \n",
    "from  albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        # Contrast Limited Adaptive Histogram Equalization 적용\n",
    "#     A.CLAHE(p=1,clip_limit=(1, 3)),\n",
    "#     A.HorizontalFlip(p=0.3),\n",
    "    A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "    A.ShiftScaleRotate(shift_limit=0, scale_limit=(0.1, 0.2), rotate_limit=0, p=0.6, border_mode=cv2.BORDER_REPLICATE),\n",
    "    A.CLAHE(clip_limit=(1, 2), p=0.6),\n",
    "    A.RandomRotate90(p=0.7),\n",
    "    A.VerticalFlip(p=0.7),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
    "    # A.Normalize()\n",
    "    ToTensorV2()\n",
    "    ])\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf8e364b-9740-43d0-a48d-a483bc280ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n",
      "52\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Aov_Dysplasia_dataset(train_normal_path, train_abnormal_path, transform = train_transform)\n",
    "valid_dataset = Aov_Dysplasia_dataset(valid_normal_path, valid_abnormal_path, transform = valid_transform)\n",
    "test_dataset = Aov_Dysplasia_dataset(test_normal_path, test_abnormal_path, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c37a4c6-5a55-4a55-9afb-3a079b3e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle = False ,worker_init_fn=seed_worker)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle = True, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d910b70c-e2f2-45e3-ab9b-5b5feb634af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2033, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13229441__2021-05-07__05d.jpg\n",
      "tensor(0.7467, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 35122850__2021-09-10__05d.jpg\n",
      "tensor(0.9121, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__05d.jpg\n",
      "tensor(0.5503, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__05d.jpg\n",
      "tensor(0.1212, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14485136__2022-04-28__05d.jpg\n",
      "tensor(0.7617, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__305d.jpg\n",
      "tensor(0.8772, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 37022026__2018-08-29__205d.jpg\n",
      "tensor(0.5960, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 19590019__2022-05-06__205d.jpg\n",
      "tensor(0.0402, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 51321147__2022-05-06__05d.jpg\n",
      "tensor(0.8107, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 35122850__2021-09-10__305d.jpg\n",
      "tensor(0.8348, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49835100__2016-04-22__05d.jpg\n",
      "tensor(0.7589, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 11472124__2017-11-29__05d.jpg\n",
      "tensor(0.1201, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14309458__2021-04-20__05d.jpg\n",
      "tensor(0.6489, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__305d.jpg\n",
      "tensor(0.1792, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13233262__2018-02-28__05d.jpg\n",
      "tensor(0.0430, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63606384__2022-05-06__05d.jpg\n",
      "tensor(0.9928, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__405d.jpg\n",
      "tensor(0.7594, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60518952__2021-08-14__205d.jpg\n",
      "tensor(0.3436, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10904750__2020-01-06__05d.jpg\n",
      "tensor(0.2356, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13233262__2021-04-02__05d.jpg\n",
      "tensor(0.0642, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2021-06-04__05d.jpg\n",
      "tensor(0.4003, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 62168416__2021-09-27__05d.jpg\n",
      "tensor(0.2146, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63760637__2022-04-28__05d.jpg\n",
      "tensor(0.1252, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11141057__2021-09-02__05d.jpg\n",
      "tensor(0.9355, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60518952__2021-08-14__305d.jpg\n",
      "tensor(0.3183, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 45035768__2022-05-06__05d.jpg\n",
      "tensor(0.1369, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 19590019__2020-02-10__05d.jpg\n",
      "tensor(0.4052, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14186624__2021-08-03__05d.jpg\n",
      "tensor(0.9221, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33071653__2019-10-07__205d.jpg\n",
      "tensor(0.3343, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13653532__2016-10-04__05d.jpg\n",
      "tensor(0.7486, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 13653532__2019-02-11__05d.jpg\n",
      "tensor(0.7868, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 54374119__2018-02-13__305d.jpg\n",
      "tensor(0.2013, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 33765112__2022-04-18__05d.jpg\n",
      "tensor(0.5883, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 35122850__2021-09-10__205d.jpg\n",
      "tensor(0.9960, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50526879__2016-02-12__05d.jpg\n",
      "tensor(0.3883, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10904750__2019-01-30__05d.jpg\n",
      "tensor(0.8011, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53011631__2020-10-22__05d.jpg\n",
      "tensor(0.1198, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 34860483__2022-05-06__05d.jpg\n",
      "tensor(0.1539, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14309458__2020-04-17__05d.jpg\n",
      "tensor(0.5549, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__205d.jpg\n",
      "tensor(0.4815, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 62333265__2021-10-05__05d.jpg\n",
      "tensor(0.5416, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 62114332__2021-09-03__05d.jpg\n",
      "tensor(0.1722, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10781135__2020-02-26__05d.jpg\n",
      "tensor(0.9133, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33071653__2019-10-07__05d.jpg\n",
      "tensor(0.9445, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 14309458__2019-04-17__05d.jpg\n",
      "tensor(0.9584, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49835100__2016-04-22__305d.jpg\n",
      "tensor(0.6273, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__205d.jpg\n",
      "tensor(0.2824, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 48219899__2022-04-27__05d.jpg\n",
      "tensor(0.2527, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 23500673__2022-03-08__05d.jpg\n",
      "tensor(0.6550, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 13989402__2018-06-18__05d.jpg\n",
      "tensor(0.4638, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13233262__2019-02-26__05d.jpg\n",
      "tensor(0.0885, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 33664062__2022-04-27__05d.jpg\n",
      "tensor(0.1703, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 50642416__2022-04-18__05d.jpg\n",
      "tensor(0.9262, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 34427437__2019-01-04__305d.jpg\n",
      "tensor(0.9549, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50526879__2016-02-12__205d.jpg\n",
      "tensor(0.0512, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 19590019__2022-05-06__05d.jpg\n",
      "tensor(0.9892, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__205d.jpg\n",
      "tensor(0.1491, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13989402__2021-06-28__05d.jpg\n",
      "tensor(0.2738, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 49835100__2016-04-22__205d.jpg\n",
      "tensor(0.1099, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2020-06-11__205d.jpg\n",
      "tensor(0.8216, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__405d.jpg\n",
      "tensor(0.2949, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 45035768__2019-05-31__05d.jpg\n",
      "tensor(0.0787, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2020-06-11__05d.jpg\n",
      "tensor(0.1640, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 29349092__2022-04-28__05d.jpg\n",
      "tensor(0.1678, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 42268381__2022-04-27__05d.jpg\n",
      "tensor(0.0830, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 19590019__2021-05-14__05d.jpg\n",
      "tensor(0.0801, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 29970799__2022-04-18__05d.jpg\n",
      "tensor(0.9719, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__05d.jpg\n",
      "tensor(0.2392, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11141057__2019-05-14__05d.jpg\n",
      "tensor(0.5482, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__405d.jpg\n",
      "tensor(0.0648, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13830416__2016-02-23__05d.jpg\n",
      "tensor(0.4078, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 54374119__2018-02-13__05d.jpg\n",
      "tensor(0.8731, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 37022026__2018-08-29__305d.jpg\n",
      "tensor(0.5303, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 10898019__2019-07-09__05d.jpg\n",
      "tensor(0.6993, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__305d.jpg\n",
      "tensor(0.0892, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 24679899__2022-04-27__05d.jpg\n",
      "tensor(0.6768, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 17146144__2021-09-01__05d.jpg\n",
      "tensor(0.0369, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 18156409__2022-04-27__05d.jpg\n",
      "tensor(0.8059, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60518952__2021-08-14__05d.jpg\n",
      "tensor(0.2236, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13830416__2018-02-27__05d.jpg\n",
      "tensor(0.2570, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 31835558__2020-06-02__05d.jpg\n",
      "tensor(0.4042, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63512162__2022-04-18__05d.jpg\n",
      "tensor(0.3566, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10522963__2018-12-27__05d.jpg\n",
      "tensor(0.1391, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 31740186__2022-04-18__05d.jpg\n",
      "tensor(0.1253, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 37022026__2018-08-29__05d.jpg\n"
     ]
    }
   ],
   "source": [
    "# final conv layer name \n",
    "# feature map을 추출할 layer를 설정\n",
    "finalconv_name = 'layer4'\n",
    "\n",
    "# inference mode\n",
    "model.eval()\n",
    "\n",
    "# number of result\n",
    "# num_result = 10\n",
    "\n",
    "\n",
    "feature_blobs = []\n",
    "\n",
    "backward_feature = []\n",
    "\n",
    "# output으로 나오는 feature를 feature_blobs에 append하도록\n",
    "def hook_feature(module, input, output):\n",
    "    feature_blobs.append(output.cpu().data.numpy())\n",
    "    \n",
    "# Grad-CAM\n",
    "def backward_hook(module, input, output):\n",
    "    backward_feature.append(output[0])\n",
    "\n",
    "    \n",
    "model._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "model._modules.get(finalconv_name).register_backward_hook(backward_hook)\n",
    "\n",
    "\n",
    "# get the sigmoid weight\n",
    "params = list(model.parameters())\n",
    "weight_sigmoid = np.squeeze(params[-2].cpu().detach().numpy()) # [1, 512]\n",
    "\n",
    "\n",
    "# generate the class activation maps\n",
    "def returnCAM(feature_conv, weight_simoid, class_idx):\n",
    "    size_upsample = (224, 224)\n",
    "    _, nc, h, w = feature_conv.shape # nc : number of channel, h: height, w: width\n",
    "    output_cam = []\n",
    "    # weight 중에서 class index에 해당하는 것만 뽑은 다음, 이를 conv feature와 곱연산\n",
    "    cam = weight_sigmoid[class_idx].dot(feature_conv.reshape((nc, h*w))) \n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "incorrect_abnormal_list =[]\n",
    "incorrect_normal_list = []\n",
    "\n",
    "for data in valid_dataloader:\n",
    "    \n",
    "    inputs = data['img'].float()\n",
    "    labels = data['label']\n",
    "    idx_list = data['filename']\n",
    "    idx = ' '.join(s for s in idx_list)\n",
    "    idx = idx.split('/')[-1]\n",
    "    \n",
    "    # 모델의 input으로 주기 위한 image는 따로 설정\n",
    "    image_for_model = inputs.clone().detach()\n",
    "\n",
    "    # Image denormalization, using mean and std that i was used.\n",
    "#     image[0][0] *= 0.2257\n",
    "#     image[0][1] *= 0.2209\n",
    "#     image[0][2] *= 0.2212\n",
    "    \n",
    "#     image[0][0] += 0.4876\n",
    "#     image[0][1] += 0.4544\n",
    "#     image[0][2] += 0.4165\n",
    "    \n",
    "\n",
    "    # 모델의 input으로 사용하도록.\n",
    "    image_tensor = image_for_model.to(device)\n",
    "    logit = model(image_tensor)\n",
    "    output = torch.squeeze(logit)\n",
    "    output_sig = torch.sigmoid(output)\n",
    "    y_pred = output_sig.cpu()\n",
    "    print(y_pred)\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "    \n",
    "    if y_pred != labels.cpu():\n",
    "        \n",
    "        if labels.cpu() == 1:\n",
    "            incorrect_abnormal_list.append(idx)\n",
    "        else:\n",
    "            incorrect_normal_list.append(idx)\n",
    "    label_out = labels.item()\n",
    "    y_pred_out = y_pred.item()\n",
    "    print(\"True label : %d, Predicted label : %d, idx : %s\" % (label_out, y_pred_out, idx))\n",
    "    \n",
    "    # ============================= #\n",
    "    # ==== Grad-CAM main lines ==== #\n",
    "    # ============================= #\n",
    "    \n",
    "    score = logit.squeeze() # 예측값 y^c\n",
    "    score.backward(retain_graph = True) # 예측값 y^c에 대해서 backprop 진행\n",
    "    \n",
    "    activations = torch.Tensor(feature_blobs[0]).to(device) # (1, 512, 7, 7), forward activations\n",
    "    gradients = backward_feature[0] # (1, 512, 7, 7), backward gradients\n",
    "    b, k, u, v = gradients.size()\n",
    "    \n",
    "    # view() 함수에서 -1은 다른 dimension에서 자동적으로 추론되는 것을 의미한다. \n",
    "    alpha = gradients.view(b, k, -1).mean(2) # (1, 512, 7*7) => (1, 512), feature map k의 'importance'\n",
    "    weights = alpha.view(b, k, 1, 1) # (1, 512, 1, 1)\n",
    "    \n",
    "    #위에서 지정해준 layer에서의 output인 activations과 backward gradients를 평균한 값인 weights를 곱해준다.\n",
    "    grad_cam_map = (weights*activations).sum(1, keepdim = True) # alpha * A^k = (1, 512, 7, 7) => (1, 1, 7, 7)\n",
    "    \n",
    "    # Apply R e L U\n",
    "    grad_cam_map = F.relu(grad_cam_map) \n",
    "    \n",
    "    grad_cam_map = F.interpolate(grad_cam_map, size=(224, 224), mode='bilinear', align_corners=False) # (1, 1, 224, 224)\n",
    "    map_min, map_max = grad_cam_map.min(), grad_cam_map.max()\n",
    "    grad_cam_map = (grad_cam_map - map_min).div(map_max - map_min).data # (1, 1, 224, 224), min-max scaling\n",
    "\n",
    "    # grad_cam_map.squeeze() : (224, 224)\n",
    "    grad_heatmap = cv2.applyColorMap(np.uint8(255 * grad_cam_map.squeeze().cpu()), cv2.COLORMAP_JET) # (224, 224, 3), numpy \n",
    "    grad_heatmap = torch.from_numpy(grad_heatmap).permute(2, 0, 1).float().div(255) # (3, 224, 224)\n",
    "    b, g, r = grad_heatmap.split(1)\n",
    "    grad_heatmap = torch.cat([r, g, b]) # (3, 244, 244), opencv's default format is BGR, so we need to change it as RGB format.\n",
    "\n",
    "    # save_image(grad_heatmap, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx_out)))\n",
    "    \n",
    "    # print(grad_heatmap.type)\n",
    "    # print(inputsinputs.cpu().type)\n",
    "    grad_result = grad_heatmap + inputs.cpu() # (1, 3, 224, 224)\n",
    "    # print(grad_result.shape)\n",
    "    grad_result = grad_result.div(grad_result.max()).squeeze() # (3, 224, 224)\n",
    "    \n",
    "    # save_image(grad_result, os.path.join(saved_loc, \"GradCAM&image_%d.jpg\" % (xhch_idx+1)))\n",
    "    \n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    image_list.append(torch.stack([inputs.squeeze().cpu(), grad_heatmap, grad_result], 0)) # (3, 3, 224, 224)\n",
    "    \n",
    "    images = make_grid(torch.cat(image_list, 0), nrow = 3)\n",
    "    \n",
    "    # image 저장\n",
    "    save_image(images, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx)))\n",
    "    \n",
    "    # if  batch_idx + 1 == num_result:\n",
    "    #     break\n",
    "        \n",
    "    feature_blobs.clear()\n",
    "    backward_feature.clear()\n",
    "\n",
    "feature_blobs.clear()\n",
    "backward_feature.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fca08dba-c1ff-428d-b474-138938b5ec98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 10626726__2020-12-17__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 10626726__2022-01-04__205d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 10626726__2022-01-04__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 10836307__2019-12-16__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 10836307__2020-12-02__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11265270__2019-02-16__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11265270__2020-06-24__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11430795__2013-07-17__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11430795__2015-07-15__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11700571__2019-02-28__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11700571__2021-04-21__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11757135__2020-02-24__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11757135__2021-02-08__205d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11757135__2022-02-14__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11829528__2018-06-05__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11829528__2019-03-29__05d.jpg\n",
      "torch.Size([11, 1, 2048, 7, 7])\n",
      "torch.Size([1, 2048, 7, 7])\n",
      "True label : 0, Predicted label : 0, idx : 11829528__2021-09-07__05d.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fe35085b3596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_blobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (1, 512, 7, 7), forward activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_blobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;31m# print(activations)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# final conv layer name \n",
    "# feature map을 추출할 layer를 설정\n",
    "finalconv_name = 'layer4'\n",
    "\n",
    "# inference mode\n",
    "model.eval()\n",
    "\n",
    "# number of result\n",
    "# num_result = 10\n",
    "\n",
    "\n",
    "feature_blobs = []\n",
    "\n",
    "backward_feature = []\n",
    "\n",
    "# output으로 나오는 feature를 feature_blobs에 append하도록\n",
    "def hook_feature(module, input, output):\n",
    "    feature_blobs.append(output.cpu().data.numpy())\n",
    "    \n",
    "    \n",
    "# Grad-CAM\n",
    "def backward_hook(module, input, output):\n",
    "    backward_feature.append(output[0])\n",
    "\n",
    "    \n",
    "model._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "model._modules.get(finalconv_name).register_backward_hook(backward_hook)\n",
    "\n",
    "\n",
    "# get the sigmoid weight\n",
    "params = list(model.parameters())\n",
    "weight_sigmoid = np.squeeze(params[-2].cpu().detach().numpy()) # [1, 512]\n",
    "\n",
    "\n",
    "# generate the class activation maps\n",
    "def returnCAM(feature_conv, weight_simoid, class_idx):\n",
    "    size_upsample = (224, 224)\n",
    "    _, nc, h, w = feature_conv.shape # nc : number of channel, h: height, w: width\n",
    "    output_cam = []\n",
    "    # weight 중에서 class index에 해당하는 것만 뽑은 다음, 이를 conv feature와 곱연산\n",
    "    cam = weight_sigmoid[class_idx].dot(feature_conv.reshape((nc, h*w))) \n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "incorrect_abnormal_list =[]\n",
    "incorrect_normal_list = []\n",
    "\n",
    "for data in test_dataloader:\n",
    "    \n",
    "    inputs = data['img']\n",
    "    labels = data['label']\n",
    "    idx_list = data['filename']\n",
    "    idx = ' '.join(s for s in idx_list)\n",
    "    idx = idx.split('/')[-1]\n",
    "    \n",
    "    # 모델의 input으로 주기 위한 image는 따로 설정\n",
    "    image_for_model = inputs.clone().detach()\n",
    "\n",
    "    # Image denormalization, using mean and std that i was used.\n",
    "#     image[0][0] *= 0.2257\n",
    "#     image[0][1] *= 0.2209\n",
    "#     image[0][2] *= 0.2212\n",
    "    \n",
    "#     image[0][0] += 0.4876\n",
    "#     image[0][1] += 0.4544\n",
    "#     image[0][2] += 0.4165\n",
    "    \n",
    "\n",
    "    # 모델의 input으로 사용하도록.\n",
    "    image_tensor = image_for_model.to(device)\n",
    "    logit = model(image_tensor)\n",
    "    output = torch.squeeze(logit)\n",
    "    output_sig = torch.sigmoid(output)\n",
    "    y_pred = output_sig.cpu()\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "    \n",
    "    if y_pred != labels.cpu():\n",
    "        \n",
    "        if labels.cpu() == 1:\n",
    "            incorrect_abnormal_list.append(idx)\n",
    "        else:\n",
    "            incorrect_normal_list.append(idx)\n",
    "    label_out = labels.item()\n",
    "    y_pred_out = y_pred.item()\n",
    "    print(\"True label : %d, Predicted label : %d, idx : %s\" % (label_out, y_pred_out, idx))\n",
    "    \n",
    "    # ============================= #\n",
    "    # ==== Grad-CAM main lines ==== #\n",
    "    # ============================= #\n",
    "    \n",
    "    score = logit.squeeze() # 예측값 y^c\n",
    "    score.backward(retain_graph = True) # 예측값 y^c에 대해서 backprop 진행\n",
    "    \n",
    "    activations = torch.Tensor(feature_blobs[0]).to(device) # (1, 512, 7, 7), forward activations\n",
    "    print(torch.Tensor(feature_blobs).shape)\n",
    "    # print(activations)\n",
    "    \n",
    "    \n",
    "    gradients = backward_feature[0] # (1, 512, 7, 7), backward gradients\n",
    "    # print(backward_feature)\n",
    "    # print(gradients)\n",
    "    b, k, u, v = gradients.size()\n",
    "    \n",
    "    # view() 함수에서 -1은 다른 dimension에서 자동적으로 추론되는 것을 의미한다. \n",
    "    alpha = gradients.view(b, k, -1).mean(2) # (1, 512, 7*7) => (1, 512), feature map k의 'importance'\n",
    "    weights = alpha.view(b, k, 1, 1) # (1, 512, 1, 1)\n",
    "    \n",
    "    #위에서 지정해준 layer에서의 output인 activations과 backward gradients를 평균한 값인 weights를 곱해준다.\n",
    "    grad_cam_map = (weights*activations).sum(1, keepdim = True) # alpha * A^k = (1, 512, 7, 7) => (1, 1, 7, 7)\n",
    "    \n",
    "    # Apply R e L U\n",
    "    grad_cam_map = F.relu(grad_cam_map) \n",
    "    \n",
    "    grad_cam_map = F.interpolate(grad_cam_map, size=(224, 224), mode='bilinear', align_corners=False) # (1, 1, 224, 224)\n",
    "    map_min, map_max = grad_cam_map.min(), grad_cam_map.max()\n",
    "    grad_cam_map = (grad_cam_map - map_min).div(map_max - map_min).data # (1, 1, 224, 224), min-max scaling\n",
    "\n",
    "    # grad_cam_map.squeeze() : (224, 224)\n",
    "    grad_heatmap = cv2.applyColorMap(np.uint8(255 * grad_cam_map.squeeze().cpu()), cv2.COLORMAP_JET) # (224, 224, 3), numpy \n",
    "    grad_heatmap = torch.from_numpy(grad_heatmap).permute(2, 0, 1).float().div(255) # (3, 224, 224)\n",
    "    # print(grad_heatmap)\n",
    "    b, g, r = grad_heatmap.split(1)\n",
    "    grad_heatmap = torch.cat([r, g, b]) # (3, 244, 244), opencv's default format is BGR, so we need to change it as RGB format.\n",
    "\n",
    "    # save_image(grad_heatmap, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx_out)))\n",
    "    \n",
    "    # print(grad_heatmap.type)\n",
    "    # print(inputsinputs.cpu().type)\n",
    "    grad_result = grad_heatmap + inputs.cpu() # (1, 3, 224, 224)\n",
    "    # print(grad_result.shape)\n",
    "    grad_result = grad_result.div(grad_result.max()).squeeze() # (3, 224, 224)\n",
    "    \n",
    "    # save_image(grad_result, os.path.join(saved_loc, \"GradCAM&image_%d.jpg\" % (xhch_idx+1)))\n",
    "    \n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    image_list.append(torch.stack([inputs.squeeze().cpu(), grad_heatmap, grad_result], 0)) # (3, 3, 224, 224)\n",
    "    \n",
    "    images = make_grid(torch.cat(image_list, 0), nrow = 3)\n",
    "    \n",
    "    # image 저장\n",
    "    # save_image(images, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx)))\n",
    "    \n",
    "    # if  batch_idx + 1 == num_result:\n",
    "    #     break\n",
    "        \n",
    "    feature_blobs.clear()\n",
    "    backward_feature.clear()\n",
    "\n",
    "feature_blobs.clear()\n",
    "backward_feature.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a3dc7-c2ff-45c5-856c-37beb359b6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
