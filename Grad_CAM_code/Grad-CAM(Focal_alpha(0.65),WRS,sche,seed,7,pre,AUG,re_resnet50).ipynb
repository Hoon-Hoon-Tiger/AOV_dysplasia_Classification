{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1334e3eb-6a25-4141-a350-c4698cbb8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from glob import glob\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,plot_confusion_matrix\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90915749-bd87-498a-9649-8f5352a6c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed(seed = 42):\n",
    "    random.seed(seed) # python random seed 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # os 자체의 seed 고정\n",
    "    np.random.seed(seed) # numpy seed 고정 \n",
    "    torch.manual_seed(seed) # torch seed 고정\n",
    "    torch.cuda.manual_seed(seed) # cudnn seed 고정\n",
    "    torch.backends.cudnn.deterministic = True # cudnn seed 고정(nn.Conv2d)\n",
    "    torch.backends.cudnn.benchmark = False # CUDA 내부 연산에서 가장 빠른 알고리즘을 찾아 수행\n",
    "\n",
    "## DataLoader worker에 대한 seed 설정\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39484847-020b-4a6f-975b-76a1d858b37d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Load(ResNet50(pretrained O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13c3db4-f528-4605-b58f-e403412538fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "resnet50_pretrained = models.resnet50(pretrained=True)\n",
    "print(resnet50_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf6d765-e9d5-48e8-95ef-ac9678762998",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 1\n",
    "num_features = resnet50_pretrained.fc.in_features\n",
    "resnet50_pretrained.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "resnet50_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980bb983-a862-4697-bba7-a14d1e715e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu?  True\n",
      "Current gpu:  0\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crop2292/anaconda3/envs/hoon/lib/python3.6/site-packages/torch/cuda/memory.py:386: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2906],\n",
      "        [0.1736],\n",
      "        [0.0941]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "print('gpu? ', torch.cuda.is_available())\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print('Current gpu: ', torch.cuda.current_device())\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')\n",
    "    \n",
    "model = resnet50_pretrained.to(device)\n",
    "x = torch.randn(3, 3, 224, 224).to(device)\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9955aef1-cbaa-4ead-a1a4-61ffb84fe8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'Resnet50(b=16,Adam,Focal_alpha(0.75),WRS,sche,seed)_weights_pt'\n",
    "model_name = 'resnet50(b=16,Adam,Focal_alpha(0.65),WRS,sche,seed,7,pre,AUG,re)_weights_pt'\n",
    "model_path = '/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/weights_file/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802b8214-935b-46b9-ae13-1c153256cacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50_pretrained.to(device)\n",
    "model.load_state_dict(torch.load(model_path + model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11562fdb-36a2-4d06-8ce7-8c14e45756e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad_CAM_code'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5122258-3647-4e4f-8158-ad6a9cbcaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 저장 위치:  /mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad-CAM_results/Grad-CAM_results(resnet50(b=16,Adam,Focal_alpha(0.65),WRS,sche,seed,7,pre,AUG,re))\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "# current_time = datetime.datetime.now() + datetime.timedelta(hours= 9)\n",
    "# current_time = current_time.strftime('%Y-%m-%d-%H:%M')\n",
    "\n",
    "\n",
    "saved_loc = os.path.join('/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad-CAM_results/Grad-CAM_results(resnet50(b=16,Adam,Focal_alpha(0.65),WRS,sche,seed,7,pre,AUG,re))', )\n",
    "if os.path.exists(saved_loc):\n",
    "    shutil.rmtree(saved_loc)\n",
    "os.mkdir(saved_loc)\n",
    "\n",
    "print(\"결과 저장 위치: \", saved_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f2cc1-104f-4bdf-9eae-1378182796eb",
   "metadata": {},
   "source": [
    "## test dataset & test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9052ec3a-63d5-434e-86fc-d7e56b63deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_path = '/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v4/data_v4_7_1/normal_train_v4/*.jpg'\n",
    "train_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v4/data_v4_7_1/abnormal_train_v4/*.jpg'\n",
    "valid_normal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v4/data_v4_7_1/normal_val_v4/*.jpg'\n",
    "valid_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v4/data_v4_7_1/abnormal_val_v4/*.jpg'\n",
    "test_normal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v4/data_v4_7_1/normal_test_v4/*.jpg'\n",
    "test_abnormal_path ='/mnt/nas100_vol2/LeeJungHoon/Aov_task_curation_data/curation_data_v4/data_v4_7_1/abnormal_test_v4/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd0baa95-76b5-499c-ae50-2a40d9632742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_normal : 419\n",
      "val_normal : 95\n",
      "test_normal : 76\n",
      "------------------------------------\n",
      "train_abnormal : 352\n",
      "val_abnormal : 75\n",
      "test_abnormal : 78\n"
     ]
    }
   ],
   "source": [
    "train_normal_glob = glob(train_normal_path)\n",
    "train_abnormal_glob = glob(train_abnormal_path)\n",
    "val_normal_glob = glob(valid_normal_path)\n",
    "val_abnormal_glob = glob(valid_abnormal_path)\n",
    "test_normal_glob = glob(test_normal_path)\n",
    "test_abnormal_glob = glob(test_abnormal_path)\n",
    "\n",
    "print('train_normal :', len(train_normal_glob))\n",
    "print('val_normal :', len(val_normal_glob))\n",
    "print('test_normal :', len(test_normal_glob))\n",
    "print('------------------------------------')\n",
    "print('train_abnormal :', len(train_abnormal_glob))\n",
    "print('val_abnormal :', len(val_abnormal_glob))\n",
    "print('test_abnormal :', len(test_abnormal_glob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f42d6c8b-427c-4346-8b62-d6719ccec9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aov_Dysplasia_dataset(Dataset):\n",
    "    def __init__(self, normal_path, abnormal_path, transform=None):\n",
    "        #생성자, 데이터를 전처리 \n",
    "        self.normal_path_list = glob(normal_path)\n",
    "        self.abnormal_path_list = glob(abnormal_path)\n",
    "        # print(len(self.normal_path_list))\n",
    "#         self.mode = mode \n",
    "    \n",
    "#         label = np.array([[0, 1], [1, 0]], dtype=np.float32)\n",
    "        \n",
    "#         self.label_list = []\n",
    "#         for i in self.normal_path_list:\n",
    "#             self.label_list.append(label[0])\n",
    "            \n",
    "#         for i in self.abnormal_path_list:\n",
    "#             self.label_list.append(label[1])\n",
    "            \n",
    "        label_policy = {\n",
    "            'normal': 0, \n",
    "            'abnormal': 1\n",
    "        }\n",
    "    \n",
    "        self.label_list= []\n",
    "        \n",
    "        for i in self.normal_path_list:\n",
    "            self.label_list.append(label_policy[\"normal\"])\n",
    "            \n",
    "        for i in self.abnormal_path_list:\n",
    "            self.label_list.append(label_policy[\"abnormal\"])\n",
    "        \n",
    "        self.total_img_path_list = self.normal_path_list + self.abnormal_path_list\n",
    "        print(len(self.total_img_path_list))\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.total_img_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = cv2.imread(self.total_img_path_list[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # img = np.array(img, dtype=np.float32)\n",
    "        #들어오는 이미지의 컬러 형태가 BGR인지 RGB인지 모르기때문에 변형\n",
    "\n",
    "        \n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=img)\n",
    "            img = transformed['image'] \n",
    "            img = torch.tensor(np.array(img), dtype=torch.float32)\n",
    "            # img = torch.FloatTensor(img)\n",
    "            img = (img - torch.min(img)) / (torch.max(img)-torch.min(img))\n",
    "            \n",
    "            return {'img': img, 'label': label, 'filename': self.total_img_path_list[idx]}\n",
    "        \n",
    "        else:\n",
    "            # img = transformed['image']\n",
    "            img = torch.tensor(np.array(img), dtype=torch.float32)\n",
    "            # img = torch.FloatTensor(img)\n",
    "            img = (img - torch.min(img)) / (torch.max(img)-torch.min(img))\n",
    "            return{'img': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f848d606-c2f5-4af8-b4de-0af8e7ae6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://albumentations.ai/docs/api_reference/augmentations/transforms/\n",
    "import albumentations as A \n",
    "from  albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        # Contrast Limited Adaptive Histogram Equalization 적용\n",
    "#     A.CLAHE(p=1,clip_limit=(1, 3)),\n",
    "#     A.HorizontalFlip(p=0.3),\n",
    "    A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "    A.ShiftScaleRotate(shift_limit=0, scale_limit=(0.1, 0.2), rotate_limit=0, p=0.6, border_mode=cv2.BORDER_REPLICATE),\n",
    "    A.CLAHE(clip_limit=(1, 2), p=0.6),\n",
    "    A.RandomRotate90(p=0.7),\n",
    "    A.VerticalFlip(p=0.7),\n",
    "    A.HorizontalFlip(p=0.7),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
    "    # A.Normalize()\n",
    "    ToTensorV2()\n",
    "    ])\n",
    "\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224,224, interpolation = cv2.INTER_AREA),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8e364b-9740-43d0-a48d-a483bc280ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771\n",
      "170\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Aov_Dysplasia_dataset(train_normal_path, train_abnormal_path, transform = train_transform)\n",
    "valid_dataset = Aov_Dysplasia_dataset(valid_normal_path, valid_abnormal_path, transform = valid_transform)\n",
    "test_dataset = Aov_Dysplasia_dataset(test_normal_path, test_abnormal_path, transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c37a4c6-5a55-4a55-9afb-3a079b3e6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle = False ,worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe186307-62ce-447c-80d1-d528a07bd0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d910b70c-e2f2-45e3-ab9b-5b5feb634af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crop2292/anaconda3/envs/hoon/lib/python3.6/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0033, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10522963__2018-12-27__05d.jpg\n",
      "tensor(0.0025, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10527052__2018-03-17__05d.jpg\n",
      "tensor(0.0002, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10527052__2019-02-16__05d.jpg\n",
      "tensor(0.3119, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10527052__2021-09-25__05d.jpg\n",
      "tensor(0.0611, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10684900__2022-04-28__05d.jpg\n",
      "tensor(0.0106, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2020-06-11__05d.jpg\n",
      "tensor(0.0979, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2020-06-11__205d.jpg\n",
      "tensor(0.0425, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2021-06-04__05d.jpg\n",
      "tensor(0.0044, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10801899__2018-12-01__05d.jpg\n",
      "tensor(5.2697e-05, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10822531__2020-01-06__05d.jpg\n",
      "tensor(0.0001, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10822531__2021-01-09__05d.jpg\n",
      "tensor(0.0002, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10822531__2022-01-08__05d.jpg\n",
      "tensor(0.1459, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10835450__2022-02-10__05d.jpg\n",
      "tensor(0.8622, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 10898019__2019-07-09__05d.jpg\n",
      "tensor(0.1083, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10912340__2022-04-18__05d.jpg\n",
      "tensor(0.1080, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11111405__2019-12-06__05d.jpg\n",
      "tensor(0.0762, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11141057__2019-05-14__05d.jpg\n",
      "tensor(0.0616, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11141057__2021-09-02__05d.jpg\n",
      "tensor(0.3195, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11410405__2018-05-02__05d.jpg\n",
      "tensor(0.7555, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 11430795__2013-07-17__05d.jpg\n",
      "tensor(0.0086, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11430795__2015-07-15__05d.jpg\n",
      "tensor(0.9982, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 11622037__2011-10-10__05d.jpg\n",
      "tensor(0.0692, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 12010435__2022-04-28__05d.jpg\n",
      "tensor(0.0161, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 12113675__2019-09-21__05d.jpg\n",
      "tensor(0.8543, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 12625262__2014-08-06__05d.jpg\n",
      "tensor(0.2040, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 12625262__2016-07-07__05d.jpg\n",
      "tensor(0.4791, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13405478__2021-06-11__05d.jpg\n",
      "tensor(0.0360, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13405478__2021-06-11__205d.jpg\n",
      "tensor(0.8703, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 13989402__2018-06-18__05d.jpg\n",
      "tensor(0.3080, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13989402__2021-06-28__05d.jpg\n",
      "tensor(0.0464, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14015373__2019-04-17__05d.jpg\n",
      "tensor(0.0026, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14015373__2020-04-27__05d.jpg\n",
      "tensor(0.0556, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14355970__2019-08-22__05d.jpg\n",
      "tensor(0.0327, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14553363__2021-02-03__05d.jpg\n",
      "tensor(0.0121, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14553363__2022-01-28__05d.jpg\n",
      "tensor(0.0035, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 15123493__2020-02-26__05d.jpg\n",
      "tensor(0.0009, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 15123493__2020-02-26__205d.jpg\n",
      "tensor(0.0114, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 15821920__2007-04-10__05d.jpg\n",
      "tensor(0.0400, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 15821920__2021-02-02__05d.jpg\n",
      "tensor(0.0052, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 15821920__2022-05-06__05d.jpg\n",
      "tensor(0.3747, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 17146144__2021-09-01__05d.jpg\n",
      "tensor(0.3492, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 21471856__2022-04-27__05d.jpg\n",
      "tensor(0.0577, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 23500673__2022-03-08__05d.jpg\n",
      "tensor(0.0351, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 23806768__2022-04-27__05d.jpg\n",
      "tensor(0.0070, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 25097748__2022-04-27__05d.jpg\n",
      "tensor(0.0070, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 26597429__2022-04-18__05d.jpg\n",
      "tensor(0.0016, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 28552686__2022-04-27__05d.jpg\n",
      "tensor(0.0844, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 28552686__2022-04-27__205d.jpg\n",
      "tensor(0.0025, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 29970799__2022-04-18__05d.jpg\n",
      "tensor(0.0104, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 33664194__2022-04-27__05d.jpg\n",
      "tensor(0.1069, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 33826233__2022-05-06__05d.jpg\n",
      "tensor(0.0160, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 34063934__2022-05-06__05d.jpg\n",
      "tensor(0.0689, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 35100052__2022-04-27__05d.jpg\n",
      "tensor(0.0180, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 36727931__2022-05-06__05d.jpg\n",
      "tensor(0.2049, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 38414387__2022-04-18__05d.jpg\n",
      "tensor(0.7319, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 40119560__2017-02-14__05d.jpg\n",
      "tensor(0.8122, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 40119560__2017-02-14__205d.jpg\n",
      "tensor(0.0539, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 40119560__2022-05-06__05d.jpg\n",
      "tensor(0.0311, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 42286303__2022-04-27__05d.jpg\n",
      "tensor(0.0137, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 42752552__2022-04-27__05d.jpg\n",
      "tensor(0.0390, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 48219899__2022-04-27__05d.jpg\n",
      "tensor(0.1518, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 50498082__2022-04-28__05d.jpg\n",
      "tensor(0.3557, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 50642416__2022-04-18__05d.jpg\n",
      "tensor(0.0002, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 51321147__2022-05-06__05d.jpg\n",
      "tensor(0.0015, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 54437584__2021-03-22__05d.jpg\n",
      "tensor(6.4811e-05, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 54437584__2021-03-22__205d.jpg\n",
      "tensor(0.0004, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 54437584__2022-05-06__05d.jpg\n",
      "tensor(0.0769, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 59277826__2022-05-06__05d.jpg\n",
      "tensor(0.0040, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 60872120__2022-04-18__05d.jpg\n",
      "tensor(0.5274, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 62358745__2021-10-12__05d.jpg\n",
      "tensor(0.0108, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 62490106__2022-05-06__05d.jpg\n",
      "tensor(0.0105, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63746282__2022-04-27__05d.jpg\n",
      "tensor(0.0761, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63760637__2022-04-28__05d.jpg\n",
      "tensor(0.5243, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 63779819__2022-05-06__05d.jpg\n",
      "tensor(0.0076, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63821758__2022-04-27__05d.jpg\n",
      "tensor(0.0106, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63827446__2022-04-28__05d.jpg\n",
      "tensor(0.9922, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53071347__2017-06-05_05d.jpg\n",
      "tensor(0.9934, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53071347__2017-06-05_205d.jpg\n",
      "tensor(0.9185, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53443656__2017-07-24_05d.jpg\n",
      "tensor(0.9712, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53443656__2017-07-24_205d.jpg\n",
      "tensor(0.9771, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53443656__2017-07-24_305d.jpg\n",
      "tensor(0.9788, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53443656__2017-07-24_405d.jpg\n",
      "tensor(0.9948, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_05d.jpg\n",
      "tensor(0.9998, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_205d.jpg\n",
      "tensor(0.9997, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_305d.jpg\n",
      "tensor(0.9997, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_405d.jpg\n",
      "tensor(0.9977, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_505d.jpg\n",
      "tensor(0.9981, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_605d.jpg\n",
      "tensor(0.9994, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_705d.jpg\n",
      "tensor(0.9999, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_805d.jpg\n",
      "tensor(1.0000, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53582359__2017-09-01_905d.jpg\n",
      "tensor(0.9962, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 54641004__2018-03-12_05d.jpg\n",
      "tensor(0.9927, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 54641004__2018-03-12_205d.jpg\n",
      "tensor(0.9182, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 58235982__2019-10-15_05d.jpg\n",
      "tensor(0.9965, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 58235982__2019-10-15_205d.jpg\n",
      "tensor(0.9995, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 58235982__2019-10-15_305d.jpg\n",
      "tensor(0.1288, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 61138412__2021-03-30_05d.jpg\n",
      "tensor(0.9715, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 61138412__2021-03-30_205d.jpg\n",
      "tensor(0.8927, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 61138412__2021-03-30_305d.jpg\n",
      "tensor(0.9855, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 61138412__2021-03-30_405d.jpg\n",
      "tensor(0.9267, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62128805__2021-08-07_05d.jpg\n",
      "tensor(0.9808, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62128805__2021-08-07_205d.jpg\n",
      "tensor(0.9782, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62128805__2021-08-07_305d.jpg\n",
      "tensor(0.9980, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 29656721__2016-04-06_05d.jpg\n",
      "tensor(0.9948, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 29656721__2016-04-06_205d.jpg\n",
      "tensor(0.9907, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 29656721__2016-04-06_305d.jpg\n",
      "tensor(0.9848, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 46429582__2013-09-26_05d.jpg\n",
      "tensor(0.6497, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 31396318__2017-02-06__205d.jpg\n",
      "tensor(0.9116, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 31884295__2020-05-21__05d.jpg\n",
      "tensor(0.5701, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 31884295__2020-05-21__205d.jpg\n",
      "tensor(0.9735, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 34427437__2019-01-04__305d.jpg\n",
      "tensor(0.9811, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 34739976__2020-12-08__05d.jpg\n",
      "tensor(0.9679, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 34739976__2020-12-08__205d.jpg\n",
      "tensor(0.9782, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 34739976__2020-12-08__305d.jpg\n",
      "tensor(0.3601, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 37022026__2018-08-29__05d.jpg\n",
      "tensor(0.8671, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 37022026__2018-08-29__205d.jpg\n",
      "tensor(0.9813, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 37022026__2018-08-29__305d.jpg\n",
      "tensor(0.9995, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 40025470__2017-04-07__05d.jpg\n",
      "tensor(0.9730, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 40025470__2017-04-07__205d.jpg\n",
      "tensor(0.9953, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 40025470__2017-04-07__305d.jpg\n",
      "tensor(0.9305, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 42761020__2017-02-20__05d.jpg\n",
      "tensor(0.9161, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 42761020__2017-02-20__205d.jpg\n",
      "tensor(0.4493, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 44181947__2019-05-08__05d.jpg\n",
      "tensor(0.7271, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 44181947__2019-05-08__205d.jpg\n",
      "tensor(0.9357, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 44788418__2022-06-16__05d.jpg\n",
      "tensor(0.9826, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 44788418__2022-06-16__205d.jpg\n",
      "tensor(0.9756, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 44788418__2022-06-16__305d.jpg\n",
      "tensor(0.8856, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49157994__2017-10-11__05d.jpg\n",
      "tensor(0.9774, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49235320__2017-02-21__05d.jpg\n",
      "tensor(0.8763, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49235320__2017-02-21__205d.jpg\n",
      "tensor(0.9821, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49235320__2017-02-21__305d.jpg\n",
      "tensor(0.7579, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50531059__2016-04-05__05d.jpg\n",
      "tensor(0.9687, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50531059__2016-04-05__205d.jpg\n",
      "tensor(0.8657, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50531059__2016-04-05__305d.jpg\n",
      "tensor(0.5602, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50531059__2016-04-05__405d.jpg\n",
      "tensor(0.9062, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53335779__2021-03-09__05d.jpg\n",
      "tensor(0.7148, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53335779__2021-03-09__205d.jpg\n",
      "tensor(0.1587, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 53679619__2021-10-28__05d.jpg\n",
      "tensor(0.3080, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 53679619__2021-10-28__205d.jpg\n",
      "tensor(0.8849, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 58848186__2021-04-02__05d.jpg\n",
      "tensor(0.9812, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 58848186__2021-04-02__205d.jpg\n",
      "tensor(0.4393, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 60525392__2021-03-25__05d.jpg\n",
      "tensor(0.8499, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60525392__2021-03-25__205d.jpg\n",
      "tensor(0.9016, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60525392__2021-03-25__305d.jpg\n",
      "tensor(0.8951, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60525392__2021-03-25__405d.jpg\n",
      "tensor(0.6942, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60525392__2021-03-25__505d.jpg\n",
      "tensor(0.9970, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62519191__2021-10-29__05d.jpg\n",
      "tensor(0.9959, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62519191__2021-10-29__205d.jpg\n",
      "tensor(0.9984, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62519191__2021-10-29__305d.jpg\n",
      "tensor(0.9784, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 62519191__2021-10-29__405d.jpg\n",
      "tensor(0.9956, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 63131501__2022-02-16__05d.jpg\n",
      "tensor(0.9954, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 63131501__2022-02-16__205d.jpg\n",
      "tensor(0.9784, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 63131501__2022-02-16__305d.jpg\n",
      "tensor(0.2351, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 31396318__2017-02-06__05d.jpg\n"
     ]
    }
   ],
   "source": [
    "# final conv layer name \n",
    "# feature map을 추출할 layer를 설정\n",
    "finalconv_name = 'layer4'\n",
    "\n",
    "# inference mode\n",
    "model.eval()\n",
    "\n",
    "# number of result\n",
    "# num_result = 10\n",
    "\n",
    "\n",
    "feature_blobs = []\n",
    "\n",
    "backward_feature = []\n",
    "\n",
    "# output으로 나오는 feature를 feature_blobs에 append하도록\n",
    "def hook_feature(module, input, output):\n",
    "    feature_blobs.append(output.cpu().data.numpy())\n",
    "    \n",
    "# Grad-CAM\n",
    "def backward_hook(module, input, output):\n",
    "    backward_feature.append(output[0])\n",
    "\n",
    "    \n",
    "model._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "model._modules.get(finalconv_name).register_backward_hook(backward_hook)\n",
    "\n",
    "\n",
    "# get the sigmoid weight\n",
    "params = list(model.parameters())\n",
    "weight_sigmoid = np.squeeze(params[-2].cpu().detach().numpy()) # [1, 512]\n",
    "\n",
    "\n",
    "# generate the class activation maps\n",
    "def returnCAM(feature_conv, weight_simoid, class_idx):\n",
    "    size_upsample = (224, 224)\n",
    "    _, nc, h, w = feature_conv.shape # nc : number of channel, h: height, w: width\n",
    "    output_cam = []\n",
    "    # weight 중에서 class index에 해당하는 것만 뽑은 다음, 이를 conv feature와 곱연산\n",
    "    cam = weight_sigmoid[class_idx].dot(feature_conv.reshape((nc, h*w))) \n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "incorrect_abnormal_list =[]\n",
    "incorrect_normal_list = []\n",
    "\n",
    "for data in test_dataloader:\n",
    "    \n",
    "    inputs = data['img'].float()\n",
    "    labels = data['label']\n",
    "    idx_list = data['filename']\n",
    "    idx = ' '.join(s for s in idx_list)\n",
    "    idx = idx.split('/')[-1]\n",
    "    \n",
    "    # 모델의 input으로 주기 위한 image는 따로 설정\n",
    "    image_for_model = inputs.clone().detach()\n",
    "\n",
    "    # Image denormalization, using mean and std that i was used.\n",
    "#     image[0][0] *= 0.2257\n",
    "#     image[0][1] *= 0.2209\n",
    "#     image[0][2] *= 0.2212\n",
    "    \n",
    "#     image[0][0] += 0.4876\n",
    "#     image[0][1] += 0.4544\n",
    "#     image[0][2] += 0.4165\n",
    "    \n",
    "\n",
    "    # 모델의 input으로 사용하도록.\n",
    "    image_tensor = image_for_model.to(device)\n",
    "    logit = model(image_tensor)\n",
    "    output = torch.squeeze(logit)\n",
    "    output_sig = torch.sigmoid(output)\n",
    "    y_pred = output_sig.cpu()\n",
    "    print(y_pred)\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "    \n",
    "    if y_pred != labels.cpu():\n",
    "        \n",
    "        if labels.cpu() == 1:\n",
    "            incorrect_abnormal_list.append(idx)\n",
    "        else:\n",
    "            incorrect_normal_list.append(idx)\n",
    "    label_out = labels.item()\n",
    "    y_pred_out = y_pred.item()\n",
    "    print(\"True label : %d, Predicted label : %d, idx : %s\" % (label_out, y_pred_out, idx))\n",
    "    \n",
    "    # ============================= #\n",
    "    # ==== Grad-CAM main lines ==== #\n",
    "    # ============================= #\n",
    "    \n",
    "    score = logit.squeeze() # 예측값 y^c\n",
    "    score.backward(retain_graph = True) # 예측값 y^c에 대해서 backprop 진행\n",
    "    \n",
    "    activations = torch.Tensor(feature_blobs[0]).to(device) # (1, 512, 7, 7), forward activations\n",
    "    gradients = backward_feature[0] # (1, 512, 7, 7), backward gradients\n",
    "    b, k, u, v = gradients.size()\n",
    "    \n",
    "    # view() 함수에서 -1은 다른 dimension에서 자동적으로 추론되는 것을 의미한다. \n",
    "    alpha = gradients.view(b, k, -1).mean(2) # (1, 512, 7*7) => (1, 512), feature map k의 'importance'\n",
    "    weights = alpha.view(b, k, 1, 1) # (1, 512, 1, 1)\n",
    "    \n",
    "    #위에서 지정해준 layer에서의 output인 activations과 backward gradients를 평균한 값인 weights를 곱해준다.\n",
    "    grad_cam_map = (weights*activations).sum(1, keepdim = True) # alpha * A^k = (1, 512, 7, 7) => (1, 1, 7, 7)\n",
    "    \n",
    "    # Apply R e L U\n",
    "    grad_cam_map = F.relu(grad_cam_map) \n",
    "    \n",
    "    grad_cam_map = F.interpolate(grad_cam_map, size=(224, 224), mode='bilinear', align_corners=False) # (1, 1, 224, 224)\n",
    "    map_min, map_max = grad_cam_map.min(), grad_cam_map.max()\n",
    "    grad_cam_map = (grad_cam_map - map_min).div(map_max - map_min).data # (1, 1, 224, 224), min-max scaling\n",
    "\n",
    "    # grad_cam_map.squeeze() : (224, 224)\n",
    "    grad_heatmap = cv2.applyColorMap(np.uint8(255 * grad_cam_map.squeeze().cpu()), cv2.COLORMAP_JET) # (224, 224, 3), numpy \n",
    "    grad_heatmap = torch.from_numpy(grad_heatmap).permute(2, 0, 1).float().div(255) # (3, 224, 224)\n",
    "    b, g, r = grad_heatmap.split(1)\n",
    "    grad_heatmap = torch.cat([r, g, b]) # (3, 244, 244), opencv's default format is BGR, so we need to change it as RGB format.\n",
    "\n",
    "    # save_image(grad_heatmap, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx_out)))\n",
    "    \n",
    "    # print(grad_heatmap.type)\n",
    "    # print(inputsinputs.cpu().type)\n",
    "    grad_result = grad_heatmap + inputs.cpu() # (1, 3, 224, 224)\n",
    "    # print(grad_result.shape)\n",
    "    grad_result = grad_result.div(grad_result.max()).squeeze() # (3, 224, 224)\n",
    "    \n",
    "    # save_image(grad_result, os.path.join(saved_loc, \"GradCAM&image_%d.jpg\" % (xhch_idx+1)))\n",
    "    \n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    image_list.append(torch.stack([inputs.squeeze().cpu(), grad_result], 0)) # (3, 3, 224, 224)\n",
    "    \n",
    "    images = make_grid(torch.cat(image_list, 0), nrow = 3)\n",
    "    \n",
    "    # image 저장\n",
    "    save_image(images, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx)))\n",
    "    \n",
    "    # if  batch_idx + 1 == num_result:\n",
    "    #     break\n",
    "        \n",
    "    feature_blobs.clear()\n",
    "    backward_feature.clear()\n",
    "\n",
    "feature_blobs.clear()\n",
    "backward_feature.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef31cce-68ad-4ad8-9167-2c26ab5a5903",
   "metadata": {},
   "source": [
    "## validation dataset에 대한 Grad-CAM 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481ee107-da2a-4844-9413-7243901796ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 저장 위치:  /mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad-CAM_results/Grad-CAM_results(Resnet_Focal(0.75)_WRS_sch_validation)\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "# current_time = datetime.datetime.now() + datetime.timedelta(hours= 9)\n",
    "# current_time = current_time.strftime('%Y-%m-%d-%H:%M')\n",
    "\n",
    "\n",
    "saved_loc = os.path.join('/mnt/nas100_vol2/LeeJungHoon/AOV_task(binary_clssification)/Model_V2/Grad-CAM_results/Grad-CAM_results(Resnet_Focal(0.75)_WRS_sch_validation)', )\n",
    "if os.path.exists(saved_loc):\n",
    "    shutil.rmtree(saved_loc)\n",
    "os.mkdir(saved_loc)\n",
    "\n",
    "print(\"결과 저장 위치: \", saved_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed74e5cf-e070-46e7-99eb-928d03437019",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle = False, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca08dba-c1ff-428d-b474-138938b5ec98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4185, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10522963__2018-12-27__05d.jpg\n",
      "tensor(0.2730, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10781135__2020-02-26__05d.jpg\n",
      "tensor(0.4659, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2020-06-11__205d.jpg\n",
      "tensor(0.1549, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2020-06-11__05d.jpg\n",
      "tensor(0.0538, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10794302__2021-06-04__05d.jpg\n",
      "tensor(0.5989, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 10898019__2019-07-09__05d.jpg\n",
      "tensor(0.0431, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10904750__2019-01-30__05d.jpg\n",
      "tensor(0.0731, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 10904750__2020-01-06__05d.jpg\n",
      "tensor(0.3107, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11141057__2019-05-14__05d.jpg\n",
      "tensor(0.0189, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11141057__2021-09-02__05d.jpg\n",
      "tensor(0.4457, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 11472124__2017-11-29__05d.jpg\n",
      "tensor(0.3340, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13229441__2021-05-07__05d.jpg\n",
      "tensor(0.2880, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13233262__2018-02-28__05d.jpg\n",
      "tensor(0.6425, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 13233262__2019-02-26__05d.jpg\n",
      "tensor(0.1733, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13233262__2021-04-02__05d.jpg\n",
      "tensor(0.1635, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13653532__2016-10-04__05d.jpg\n",
      "tensor(0.0714, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13653532__2019-02-11__05d.jpg\n",
      "tensor(0.1092, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13830416__2016-02-23__05d.jpg\n",
      "tensor(0.0793, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13830416__2018-02-27__05d.jpg\n",
      "tensor(0.5421, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 13989402__2018-06-18__05d.jpg\n",
      "tensor(0.1070, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 13989402__2021-06-28__05d.jpg\n",
      "tensor(0.0793, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14186624__2021-08-03__05d.jpg\n",
      "tensor(0.9908, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 14309458__2019-04-17__05d.jpg\n",
      "tensor(0.0466, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14309458__2020-04-17__05d.jpg\n",
      "tensor(0.0110, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14309458__2021-04-20__05d.jpg\n",
      "tensor(0.0341, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 14485136__2022-04-28__05d.jpg\n",
      "tensor(0.2582, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 17146144__2021-09-01__05d.jpg\n",
      "tensor(0.0089, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 18156409__2022-04-27__05d.jpg\n",
      "tensor(0.1319, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 19590019__2020-02-10__05d.jpg\n",
      "tensor(0.0247, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 19590019__2021-05-14__05d.jpg\n",
      "tensor(0.5150, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 19590019__2022-05-06__205d.jpg\n",
      "tensor(0.1091, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 19590019__2022-05-06__05d.jpg\n",
      "tensor(0.0185, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 23500673__2022-03-08__05d.jpg\n",
      "tensor(0.0404, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 24679899__2022-04-27__05d.jpg\n",
      "tensor(0.0209, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 29349092__2022-04-28__05d.jpg\n",
      "tensor(0.0468, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 29970799__2022-04-18__05d.jpg\n",
      "tensor(0.1354, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 31740186__2022-04-18__05d.jpg\n",
      "tensor(0.0061, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 33664062__2022-04-27__05d.jpg\n",
      "tensor(0.0128, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 33765112__2022-04-18__05d.jpg\n",
      "tensor(0.1698, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 34860483__2022-05-06__05d.jpg\n",
      "tensor(0.2224, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 42268381__2022-04-27__05d.jpg\n",
      "tensor(0.1475, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 45035768__2019-05-31__05d.jpg\n",
      "tensor(0.0688, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 45035768__2022-05-06__05d.jpg\n",
      "tensor(0.0493, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 48219899__2022-04-27__05d.jpg\n",
      "tensor(0.1653, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 50642416__2022-04-18__05d.jpg\n",
      "tensor(0.0055, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 51321147__2022-05-06__05d.jpg\n",
      "tensor(0.6663, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 62114332__2021-09-03__05d.jpg\n",
      "tensor(0.6526, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 1, idx : 62168416__2021-09-27__05d.jpg\n",
      "tensor(0.4884, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 62333265__2021-10-05__05d.jpg\n",
      "tensor(0.3018, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63512162__2022-04-18__05d.jpg\n",
      "tensor(0.0055, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63606384__2022-05-06__05d.jpg\n",
      "tensor(0.0082, grad_fn=<ToCopyBackward0>)\n",
      "True label : 0, Predicted label : 0, idx : 63760637__2022-04-28__05d.jpg\n",
      "tensor(0.6472, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__205d.jpg\n",
      "tensor(0.6383, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__305d.jpg\n",
      "tensor(0.7612, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 18363043__2018-09-15__405d.jpg\n",
      "tensor(0.4289, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 18363043__2018-09-15__05d.jpg\n",
      "tensor(0.5782, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 31835558__2020-06-02__05d.jpg\n",
      "tensor(0.8360, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33071653__2019-10-07__205d.jpg\n",
      "tensor(0.8661, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33071653__2019-10-07__05d.jpg\n",
      "tensor(0.7339, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__205d.jpg\n",
      "tensor(0.7413, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__305d.jpg\n",
      "tensor(0.9539, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__405d.jpg\n",
      "tensor(0.7251, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 33818838__2018-10-16__05d.jpg\n",
      "tensor(0.9886, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 34427437__2019-01-04__305d.jpg\n",
      "tensor(0.4946, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 35122850__2021-09-10__205d.jpg\n",
      "tensor(0.8696, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 35122850__2021-09-10__305d.jpg\n",
      "tensor(0.7799, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 35122850__2021-09-10__05d.jpg\n",
      "tensor(0.9715, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 37022026__2018-08-29__205d.jpg\n",
      "tensor(0.9652, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 37022026__2018-08-29__305d.jpg\n",
      "tensor(0.1468, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 37022026__2018-08-29__05d.jpg\n",
      "tensor(0.4189, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 49835100__2016-04-22__205d.jpg\n",
      "tensor(0.9773, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49835100__2016-04-22__305d.jpg\n",
      "tensor(0.5865, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 49835100__2016-04-22__05d.jpg\n",
      "tensor(0.9976, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50526879__2016-02-12__205d.jpg\n",
      "tensor(0.9970, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 50526879__2016-02-12__05d.jpg\n",
      "tensor(0.5232, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 54374119__2018-02-13__305d.jpg\n",
      "tensor(0.3318, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 0, idx : 54374119__2018-02-13__05d.jpg\n",
      "tensor(0.9862, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__205d.jpg\n",
      "tensor(0.9749, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__305d.jpg\n",
      "tensor(0.9939, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__405d.jpg\n",
      "tensor(0.9651, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 56400216__2021-02-17__05d.jpg\n",
      "tensor(0.7308, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60518952__2021-08-14__205d.jpg\n",
      "tensor(0.8435, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60518952__2021-08-14__305d.jpg\n",
      "tensor(0.7701, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 60518952__2021-08-14__05d.jpg\n",
      "tensor(0.5546, grad_fn=<ToCopyBackward0>)\n",
      "True label : 1, Predicted label : 1, idx : 53011631__2020-10-22__05d.jpg\n"
     ]
    }
   ],
   "source": [
    "# final conv layer name \n",
    "# feature map을 추출할 layer를 설정\n",
    "finalconv_name = 'layer4'\n",
    "\n",
    "# inference mode\n",
    "model.eval()\n",
    "\n",
    "# number of result\n",
    "# num_result = 10\n",
    "\n",
    "\n",
    "feature_blobs = []\n",
    "\n",
    "backward_feature = []\n",
    "\n",
    "# output으로 나오는 feature를 feature_blobs에 append하도록\n",
    "def hook_feature(module, input, output):\n",
    "    feature_blobs.append(output.cpu().data.numpy())\n",
    "    \n",
    "# Grad-CAM\n",
    "def backward_hook(module, input, output):\n",
    "    backward_feature.append(output[0])\n",
    "\n",
    "    \n",
    "model._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "model._modules.get(finalconv_name).register_backward_hook(backward_hook)\n",
    "\n",
    "\n",
    "# get the sigmoid weight\n",
    "params = list(model.parameters())\n",
    "weight_sigmoid = np.squeeze(params[-2].cpu().detach().numpy()) # [1, 512]\n",
    "\n",
    "\n",
    "# generate the class activation maps\n",
    "def returnCAM(feature_conv, weight_simoid, class_idx):\n",
    "    size_upsample = (224, 224)\n",
    "    _, nc, h, w = feature_conv.shape # nc : number of channel, h: height, w: width\n",
    "    output_cam = []\n",
    "    # weight 중에서 class index에 해당하는 것만 뽑은 다음, 이를 conv feature와 곱연산\n",
    "    cam = weight_sigmoid[class_idx].dot(feature_conv.reshape((nc, h*w))) \n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "incorrect_abnormal_list =[]\n",
    "incorrect_normal_list = []\n",
    "\n",
    "for data in valid_dataloader:\n",
    "    \n",
    "    inputs = data['img'].float()\n",
    "    labels = data['label']\n",
    "    idx_list = data['filename']\n",
    "    idx = ' '.join(s for s in idx_list)\n",
    "    idx = idx.split('/')[-1]\n",
    "    \n",
    "    # 모델의 input으로 주기 위한 image는 따로 설정\n",
    "    image_for_model = inputs.clone().detach()\n",
    "\n",
    "    # Image denormalization, using mean and std that i was used.\n",
    "#     image[0][0] *= 0.2257\n",
    "#     image[0][1] *= 0.2209\n",
    "#     image[0][2] *= 0.2212\n",
    "    \n",
    "#     image[0][0] += 0.4876\n",
    "#     image[0][1] += 0.4544\n",
    "#     image[0][2] += 0.4165\n",
    "    \n",
    "\n",
    "    # 모델의 input으로 사용하도록.\n",
    "    image_tensor = image_for_model.to(device)\n",
    "    logit = model(image_tensor)\n",
    "    output = torch.squeeze(logit)\n",
    "    output_sig = torch.sigmoid(output)\n",
    "    y_pred = output_sig.cpu()\n",
    "    print(y_pred)\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred < 0.5] = 0\n",
    "    \n",
    "    if y_pred != labels.cpu():\n",
    "        \n",
    "        if labels.cpu() == 1:\n",
    "            incorrect_abnormal_list.append(idx)\n",
    "        else:\n",
    "            incorrect_normal_list.append(idx)\n",
    "    label_out = labels.item()\n",
    "    y_pred_out = y_pred.item()\n",
    "    print(\"True label : %d, Predicted label : %d, idx : %s\" % (label_out, y_pred_out, idx))\n",
    "    \n",
    "    # ============================= #\n",
    "    # ==== Grad-CAM main lines ==== #\n",
    "    # ============================= #\n",
    "    \n",
    "    score = logit.squeeze() # 예측값 y^c\n",
    "    score.backward(retain_graph = True) # 예측값 y^c에 대해서 backprop 진행\n",
    "    \n",
    "    activations = torch.Tensor(feature_blobs[0]).to(device) # (1, 512, 7, 7), forward activations\n",
    "    gradients = backward_feature[0] # (1, 512, 7, 7), backward gradients\n",
    "    b, k, u, v = gradients.size()\n",
    "    \n",
    "    # view() 함수에서 -1은 다른 dimension에서 자동적으로 추론되는 것을 의미한다. \n",
    "    alpha = gradients.view(b, k, -1).mean(2) # (1, 512, 7*7) => (1, 512), feature map k의 'importance'\n",
    "    weights = alpha.view(b, k, 1, 1) # (1, 512, 1, 1)\n",
    "    \n",
    "    #위에서 지정해준 layer에서의 output인 activations과 backward gradients를 평균한 값인 weights를 곱해준다.\n",
    "    grad_cam_map = (weights*activations).sum(1, keepdim = True) # alpha * A^k = (1, 512, 7, 7) => (1, 1, 7, 7)\n",
    "    \n",
    "    # Apply R e L U\n",
    "    grad_cam_map = F.relu(grad_cam_map) \n",
    "    \n",
    "    grad_cam_map = F.interpolate(grad_cam_map, size=(224, 224), mode='bilinear', align_corners=False) # (1, 1, 224, 224)\n",
    "    map_min, map_max = grad_cam_map.min(), grad_cam_map.max()\n",
    "    grad_cam_map = (grad_cam_map - map_min).div(map_max - map_min).data # (1, 1, 224, 224), min-max scaling\n",
    "\n",
    "    # grad_cam_map.squeeze() : (224, 224)\n",
    "    grad_heatmap = cv2.applyColorMap(np.uint8(255 * grad_cam_map.squeeze().cpu()), cv2.COLORMAP_JET) # (224, 224, 3), numpy \n",
    "    grad_heatmap = torch.from_numpy(grad_heatmap).permute(2, 0, 1).float().div(255) # (3, 224, 224)\n",
    "    b, g, r = grad_heatmap.split(1)\n",
    "    grad_heatmap = torch.cat([r, g, b]) # (3, 244, 244), opencv's default format is BGR, so we need to change it as RGB format.\n",
    "\n",
    "    # save_image(grad_heatmap, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx_out)))\n",
    "    \n",
    "    # print(grad_heatmap.type)\n",
    "    # print(inputsinputs.cpu().type)\n",
    "    grad_result = grad_heatmap + inputs.cpu() # (1, 3, 224, 224)\n",
    "    # print(grad_result.shape)\n",
    "    grad_result = grad_result.div(grad_result.max()).squeeze() # (3, 224, 224)\n",
    "    \n",
    "    # save_image(grad_result, os.path.join(saved_loc, \"GradCAM&image_%d.jpg\" % (xhch_idx+1)))\n",
    "    \n",
    "    \n",
    "    image_list = []\n",
    "    \n",
    "    image_list.append(torch.stack([inputs.squeeze().cpu(), grad_heatmap, grad_result], 0)) # (3, 3, 224, 224)\n",
    "    \n",
    "    images = make_grid(torch.cat(image_list, 0), nrow = 3)\n",
    "    \n",
    "    # image 저장\n",
    "    save_image(images, os.path.join(saved_loc, \"%d_%d_%s\" % (label_out, y_pred_out, idx)))\n",
    "    \n",
    "    # if  batch_idx + 1 == num_result:\n",
    "    #     break\n",
    "        \n",
    "    feature_blobs.clear()\n",
    "    backward_feature.clear()\n",
    "\n",
    "feature_blobs.clear()\n",
    "backward_feature.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379b17d-f555-44de-b652-74d366f83162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
